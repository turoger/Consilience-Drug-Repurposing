{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions for FB15k\n",
    "Generate predictions for FB15k and store the as a collated dataframe for a set of given predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "import pykeen.datasets\n",
    "import pykeen.models\n",
    "import pykeen.predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import polars as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/datasets/base.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  metadata = torch.load(metadata_path) if metadata_path.is_file() else None\n"
     ]
    }
   ],
   "source": [
    "dataset = pykeen.datasets.get_dataset(dataset=\"FB15k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TransE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18651/1044490615.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  transe_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load transe model\n",
    "transe_model = pykeen.models.TransE(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=1000,\n",
    "    scoring_fct_norm=2,\n",
    "    random_seed=2747481262,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "transe_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\n",
    "        \"TransE_FB15k_2.pt\"\n",
    "    ),  # accidentally deleted original. rm is sometimes dangerous\n",
    ")\n",
    "# attach state to model\n",
    "transe_model.load_state_dict(transe_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RotatE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18651/1772605041.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rotate_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load rotate model\n",
    "rotate_model = pykeen.models.RotatE(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=500,  # Note this is half the size of the actual embedding dim listed because rotate doubles the embedding dim\n",
    "    random_seed=4055375379,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "rotate_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"RotatE_FB15k.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "rotate_model.load_state_dict(transe_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ComplEx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18651/3856652078.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  complex_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load rotate model\n",
    "complex_model = pykeen.models.ComplEx(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=1000,\n",
    "    random_seed=1518493774,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    "    regularizer_kwargs=dict(weight=0.000002, p=3),\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "complex_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"ComplEx_FB15k.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "complex_model.load_state_dict(complex_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DistMult model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18651/1461738984.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  distmult_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load rotate model\n",
    "distmult_model = pykeen.models.DistMult(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=2000,\n",
    "    random_seed=1373867215,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    "    regularizer_kwargs=dict(weight=0.000002, p=3),\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "distmult_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"DistMult_FB15k_1.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "distmult_model.load_state_dict(distmult_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on a fixed test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how many nodes and relations are there that we can sample against?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Nodes: 14,951'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of Nodes: {dataset.num_entities:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Relations: 1,345'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of Relations: {dataset.num_relations:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_label</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>relation_label</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/m/010016</td>\n",
       "      <td>797</td>\n",
       "      <td>/location/hud_foreclosure_area/estimated_numbe...</td>\n",
       "      <td>13352</td>\n",
       "      <td>/m/0jbk9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/m/0100mt</td>\n",
       "      <td>707</td>\n",
       "      <td>/government/governmental_jurisdiction/governin...</td>\n",
       "      <td>14425</td>\n",
       "      <td>/m/0pqc5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>/m/0100mt</td>\n",
       "      <td>799</td>\n",
       "      <td>/location/hud_foreclosure_area/hhuniv./measure...</td>\n",
       "      <td>13352</td>\n",
       "      <td>/m/0jbk9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>/m/0100mt</td>\n",
       "      <td>800</td>\n",
       "      <td>/location/hud_foreclosure_area/total_90_day_va...</td>\n",
       "      <td>13352</td>\n",
       "      <td>/m/0jbk9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>/m/0100mt</td>\n",
       "      <td>810</td>\n",
       "      <td>/location/location/people_born_here</td>\n",
       "      <td>2129</td>\n",
       "      <td>/m/01mmslz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59066</th>\n",
       "      <td>14944</td>\n",
       "      <td>/m/0zpfy</td>\n",
       "      <td>416</td>\n",
       "      <td>/common/topic/webpage./common/webpage/category</td>\n",
       "      <td>10505</td>\n",
       "      <td>/m/08mbj5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59067</th>\n",
       "      <td>14945</td>\n",
       "      <td>/m/0zq7r</td>\n",
       "      <td>416</td>\n",
       "      <td>/common/topic/webpage./common/webpage/category</td>\n",
       "      <td>10505</td>\n",
       "      <td>/m/08mbj5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59068</th>\n",
       "      <td>14947</td>\n",
       "      <td>/m/0zqq8</td>\n",
       "      <td>797</td>\n",
       "      <td>/location/hud_foreclosure_area/estimated_numbe...</td>\n",
       "      <td>13352</td>\n",
       "      <td>/m/0jbk9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59069</th>\n",
       "      <td>14947</td>\n",
       "      <td>/m/0zqq8</td>\n",
       "      <td>804</td>\n",
       "      <td>/location/location/containedby</td>\n",
       "      <td>14112</td>\n",
       "      <td>/m/0mww2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59070</th>\n",
       "      <td>14947</td>\n",
       "      <td>/m/0zqq8</td>\n",
       "      <td>813</td>\n",
       "      <td>/location/location/time_zones</td>\n",
       "      <td>4500</td>\n",
       "      <td>/m/02hcv8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59071 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       head_id head_label  relation_id  \\\n",
       "0            0  /m/010016          797   \n",
       "1            1  /m/0100mt          707   \n",
       "2            1  /m/0100mt          799   \n",
       "3            1  /m/0100mt          800   \n",
       "4            1  /m/0100mt          810   \n",
       "...        ...        ...          ...   \n",
       "59066    14944   /m/0zpfy          416   \n",
       "59067    14945   /m/0zq7r          416   \n",
       "59068    14947   /m/0zqq8          797   \n",
       "59069    14947   /m/0zqq8          804   \n",
       "59070    14947   /m/0zqq8          813   \n",
       "\n",
       "                                          relation_label  tail_id  tail_label  \n",
       "0      /location/hud_foreclosure_area/estimated_numbe...    13352    /m/0jbk9  \n",
       "1      /government/governmental_jurisdiction/governin...    14425    /m/0pqc5  \n",
       "2      /location/hud_foreclosure_area/hhuniv./measure...    13352    /m/0jbk9  \n",
       "3      /location/hud_foreclosure_area/total_90_day_va...    13352    /m/0jbk9  \n",
       "4                    /location/location/people_born_here     2129  /m/01mmslz  \n",
       "...                                                  ...      ...         ...  \n",
       "59066     /common/topic/webpage./common/webpage/category    10505  /m/08mbj5d  \n",
       "59067     /common/topic/webpage./common/webpage/category    10505  /m/08mbj5d  \n",
       "59068  /location/hud_foreclosure_area/estimated_numbe...    13352    /m/0jbk9  \n",
       "59069                     /location/location/containedby    14112    /m/0mww2  \n",
       "59070                      /location/location/time_zones     4500   /m/02hcv8  \n",
       "\n",
       "[59071 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of testing triples and their correct answers\n",
    "dataset.testing.tensor_to_df(dataset.testing.mapped_triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test triples (at least a small set of it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   797, 13352],\n",
       "        [    1,   707, 14425],\n",
       "        [    1,   799, 13352],\n",
       "        ...,\n",
       "        [14947,   797, 13352],\n",
       "        [14947,   804, 14112],\n",
       "        [14947,   813,  4500]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how the tensor looks\n",
    "dataset.testing.mapped_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59071, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the tensor\n",
    "dataset.testing.mapped_triples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1000 random indices to slice the testing triples\n",
    "random_ind = np.random.choice(\n",
    "    np.array(range(0, dataset.testing.mapped_triples.shape[0])), 1000, replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sliced tensor of testing triples\n",
    "dataset.testing.mapped_triples[random_ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists of triples\n",
    "# [[head, relation, tail], ...]\n",
    "test_set = dataset.testing.mapped_triples[random_ind].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get top 1000 predictions in our random sample.\n",
    "* May or may not be exactly 1000 unique entity/relation combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first generate a prediction for a given triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top predictions for the first entry in the test set\n",
    "adf = pykeen.predict.predict_target(\n",
    "    model=transe_model,\n",
    "    triples_factory=dataset,\n",
    "    head=test_set[0][0],\n",
    "    relation=test_set[0][1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate the entity ids to their actual names\n",
    "adf.df[\"tail_id\"] = adf.df[\"tail_id\"].apply(\n",
    "    lambda x: {v: k for k, v in adf.factory.entity_to_id.items()}[x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tail_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8648</th>\n",
       "      <td>/m/05ls3r</td>\n",
       "      <td>-23.525023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13214</th>\n",
       "      <td>/m/0hmt3</td>\n",
       "      <td>-23.545902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13454</th>\n",
       "      <td>/m/0jnl5</td>\n",
       "      <td>-23.549711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>/m/04l5d0</td>\n",
       "      <td>-23.551441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>/m/048ldh</td>\n",
       "      <td>-23.552189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tail_id      score\n",
       "8648   /m/05ls3r -23.525023\n",
       "13214   /m/0hmt3 -23.545902\n",
       "13454   /m/0jnl5 -23.549711\n",
       "7751   /m/04l5d0 -23.551441\n",
       "7384   /m/048ldh -23.552189"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adf.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14951, 4)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adf.df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### can we implement it in polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "polars_df = pl.DataFrame(adf.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tail_id</th><th>score</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>8648</td><td>-23.525023</td></tr><tr><td>13214</td><td>-23.545902</td></tr><tr><td>13454</td><td>-23.549711</td></tr><tr><td>7751</td><td>-23.551441</td></tr><tr><td>7384</td><td>-23.552189</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────┬────────────┐\n",
       "│ tail_id ┆ score      │\n",
       "│ ---     ┆ ---        │\n",
       "│ i64     ┆ f64        │\n",
       "╞═════════╪════════════╡\n",
       "│ 8648    ┆ -23.525023 │\n",
       "│ 13214   ┆ -23.545902 │\n",
       "│ 13454   ┆ -23.549711 │\n",
       "│ 7751    ┆ -23.551441 │\n",
       "│ 7384    ┆ -23.552189 │\n",
       "└─────────┴────────────┘"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of entities and relations\n",
    "id2entity = {str(v): k for k, v in adf.factory.entity_to_id.items()}\n",
    "id2relation = {str(v): k for k, v in adf.factory.relation_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars function to replace the ids with their actual names and aggregate results as a list\n",
    "# 25 s to do the groupby and replace\n",
    "\n",
    "res_ls = []\n",
    "for i in test_set:\n",
    "    polars_df = polars_df.with_columns(\n",
    "        pl.col(\"score\").sort(descending=True), head_id=i[0], rel_id=i[1]\n",
    "    ).with_columns(\n",
    "        pl.col(\"tail_id\").cast(pl.String).replace(id2entity),\n",
    "        pl.col(\"head_id\").cast(pl.String).replace(id2entity),\n",
    "        pl.col(\"rel_id\").cast(pl.String).replace(id2relation),\n",
    "    )\n",
    "\n",
    "    res_ls.append(polars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (949, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>head_id</th><th>rel_id</th><th>tail_id</th><th>maintain_order</th></tr><tr><td>str</td><td>str</td><td>list[str]</td><td>bool</td></tr></thead><tbody><tr><td>&quot;/m/04pg29&quot;</td><td>&quot;/tv/tv_program…</td><td>[&quot;/m/0356gk&quot;, &quot;/m/096cw_&quot;, … &quot;/m/02vl_pz&quot;]</td><td>true</td></tr><tr><td>&quot;/m/07t3gd&quot;</td><td>&quot;/business/job_…</td><td>[&quot;/m/01j95f&quot;, &quot;/m/03l7tr&quot;, … &quot;/m/03vtbc&quot;]</td><td>true</td></tr><tr><td>&quot;/m/02rdyk7&quot;</td><td>&quot;/award/award_c…</td><td>[&quot;/m/01kkg5&quot;, &quot;/m/0122wc&quot;, … &quot;/m/0bgv4g&quot;]</td><td>true</td></tr><tr><td>&quot;/m/05zksls&quot;</td><td>&quot;/award/award_c…</td><td>[&quot;/m/01k9cc&quot;, &quot;/m/03lpp_&quot;, … &quot;/m/03h42s4&quot;]</td><td>true</td></tr><tr><td>&quot;/m/05k7sb&quot;</td><td>&quot;/location/loca…</td><td>[&quot;/m/03j0ss&quot;, &quot;/m/03__77&quot;, … &quot;/m/0fp_xp&quot;]</td><td>true</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;/m/01t265&quot;</td><td>&quot;/people/person…</td><td>[&quot;/m/09hldj&quot;, &quot;/m/06jd89&quot;, … &quot;/m/080dyk&quot;]</td><td>true</td></tr><tr><td>&quot;/m/0178_w&quot;</td><td>&quot;/music/musical…</td><td>[&quot;/m/044l47&quot;, &quot;/m/01slcv&quot;, … &quot;/m/02cg2v&quot;]</td><td>true</td></tr><tr><td>&quot;/m/09p4w8&quot;</td><td>&quot;/film/film/sta…</td><td>[&quot;/m/0303jw&quot;, &quot;/m/02rh_0&quot;, … &quot;/m/02vx4&quot;]</td><td>true</td></tr><tr><td>&quot;/m/054lpb6&quot;</td><td>&quot;/film/film_dis…</td><td>[&quot;/m/03v9yw&quot;, &quot;/m/01bdxz&quot;, … &quot;/m/05b3ts&quot;]</td><td>true</td></tr><tr><td>&quot;/m/03gfvsz&quot;</td><td>&quot;/broadcast/con…</td><td>[&quot;/m/03078l&quot;, &quot;/m/013xh7&quot;, … &quot;/m/01sdzg&quot;]</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (949, 4)\n",
       "┌────────────┬─────────────────────────────────────┬──────────────────────────────┬────────────────┐\n",
       "│ head_id    ┆ rel_id                              ┆ tail_id                      ┆ maintain_order │\n",
       "│ ---        ┆ ---                                 ┆ ---                          ┆ ---            │\n",
       "│ str        ┆ str                                 ┆ list[str]                    ┆ bool           │\n",
       "╞════════════╪═════════════════════════════════════╪══════════════════════════════╪════════════════╡\n",
       "│ /m/04pg29  ┆ /tv/tv_program_creator/programs_…   ┆ [\"/m/0356gk\", \"/m/096cw_\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ /m/07t3gd  ┆ /business/job_title/people_with_…   ┆ [\"/m/01j95f\", \"/m/03l7tr\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ /m/02rdyk7 ┆ /award/award_category/nominees./…   ┆ [\"/m/01kkg5\", \"/m/0122wc\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ /m/05zksls ┆ /award/award_ceremony/awards_pre…   ┆ [\"/m/01k9cc\", \"/m/03lpp_\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ /m/05k7sb  ┆ /location/location/contains         ┆ [\"/m/03j0ss\", \"/m/03__77\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ …          ┆ …                                   ┆ …                            ┆ …              │\n",
       "│ /m/01t265  ┆ /people/person/places_lived./peo…   ┆ [\"/m/09hldj\", \"/m/06jd89\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ /m/0178_w  ┆ /music/musical_group/member./mus…   ┆ [\"/m/044l47\", \"/m/01slcv\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ /m/09p4w8  ┆ /film/film/starring./film/perfor…   ┆ [\"/m/0303jw\", \"/m/02rh_0\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ /m/054lpb6 ┆ /film/film_distributor/films_dis…   ┆ [\"/m/03v9yw\", \"/m/01bdxz\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "│ /m/03gfvsz ┆ /broadcast/content/artist           ┆ [\"/m/03078l\", \"/m/013xh7\", … ┆ true           │\n",
       "│            ┆                                     ┆ \"/m…                         ┆                │\n",
       "└────────────┴─────────────────────────────────────┴──────────────────────────────┴────────────────┘"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of the results. its 2-3x faster than pandas\n",
    "pl.concat(res_ls).unique([\"head_id\", \"rel_id\", \"tail_id\"]).group_by(\n",
    "    [\"head_id\", \"rel_id\"]\n",
    ").agg(\"tail_id\", maintain_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate predictions on a bigger scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write afunction to make predictions on the models\n",
    "def get_top_tail_predictions(model, test_set, dataset, k=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a model, and a test set, return the top predictions for the test set\n",
    "\n",
    "    model: pykeen.models.Model\n",
    "    test_set: list of lists of triples [[head, relation, tail], ...]\n",
    "    dataset: pykeen.datasets.dataset.TriplesFactory\n",
    "    k: int, number of top predictions to return\n",
    "\n",
    "    returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # create dictionaries for entities and relations\n",
    "    id2entity = {v: k for k, v in dataset.entity_to_id.items()}\n",
    "    id2relation = {v: k for k, v in dataset.relation_to_id.items()}\n",
    "\n",
    "    # get the top predictions for the first entry in the test set\n",
    "    res_ls = []\n",
    "    for i in test_set:\n",
    "        # generate predictions and cast to a polars dataframe\n",
    "        polars_df = pl.DataFrame(\n",
    "            pykeen.predict.predict_target(\n",
    "                model=model, triples_factory=dataset, head=i[0], relation=i[1]\n",
    "            ).df\n",
    "        )\n",
    "        # sort the predictions by score, add head and relation ids\n",
    "        polars_df = polars_df.with_columns(\n",
    "            pl.col(\"score\").sort(descending=True),\n",
    "            head_id=i[0],  # assign head_id\n",
    "            rel_id=i[1],  # assign relation_id\n",
    "        )\n",
    "        res_ls.append(polars_df)\n",
    "\n",
    "    # rename entities in head/tail/relation from ids to actual names\n",
    "    # collapse tail_ids to a single row based on head and relation_ids\n",
    "    res_df = (\n",
    "        pl.concat(res_ls)\n",
    "        .with_columns(\n",
    "            # rename entities in head/tail/relation from ids to actual names\n",
    "            pl.col(\"tail_id\").cast(pl.String).replace(id2entity),\n",
    "            pl.col(\"head_id\").cast(pl.String).replace(id2entity),\n",
    "            pl.col(\"rel_id\").cast(pl.String).replace(id2relation),\n",
    "        )\n",
    "        .unique([\"head_id\", \"rel_id\", \"tail_id\"])\n",
    "        .group_by([\"head_id\", \"rel_id\"])\n",
    "        .agg(\"tail_id\", maintain_order=True)\n",
    "    )\n",
    "\n",
    "    # return top k predictions\n",
    "    if k > 0:\n",
    "        res_df = res_df.with_columns(pl.col(\"tail_id\").list.head(k))\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "transe_df = get_top_tail_predictions(transe_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "distumult_df = get_top_tail_predictions(distmult_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_df = get_top_tail_predictions(complex_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_df = get_top_tail_predictions(rotate_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add column name identifier to each dataframe.\n",
    "* then stack them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "transe_df = transe_df.with_columns(model=pl.lit(\"TransE\"))\n",
    "distumult_df = distumult_df.with_columns(model=pl.lit(\"DistMult\"))\n",
    "complex_df = complex_df.with_columns(model=pl.lit(\"ComplEx\"))\n",
    "rotate_df = rotate_df.with_columns(model=pl.lit(\"RotatE\"))\n",
    "\n",
    "# combine the results\n",
    "combined_df = pl.concat([transe_df, distumult_df, complex_df, rotate_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>head_id</th><th>rel_id</th><th>tail_id</th><th>maintain_order</th><th>model</th></tr><tr><td>str</td><td>str</td><td>list[str]</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;/m/089g0h&quot;</td><td>&quot;/film/film_job…</td><td>[&quot;/m/03h4fq7&quot;, &quot;/m/09hy79&quot;, … &quot;/m/0l2lk&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;/m/01whg97&quot;</td><td>&quot;/people/person…</td><td>[&quot;/m/0f2v0&quot;, &quot;/m/0dc95&quot;, … &quot;/m/0fgsq2&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;/m/0jm3b&quot;</td><td>&quot;/sports/profes…</td><td>[&quot;/m/0mbwf&quot;, &quot;/m/01hr11&quot;, … &quot;/m/0mhl6&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;/m/03h304l&quot;</td><td>&quot;/film/producer…</td><td>[&quot;/m/02sfnv&quot;, &quot;/m/057__d&quot;, … &quot;/m/01gc7h&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;/m/037jz&quot;</td><td>&quot;/influence/inf…</td><td>[&quot;/m/073bb&quot;, &quot;/m/059y0&quot;, … &quot;/m/0br1x_&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────────┬─────────────────────────────┬─────────────────────────────┬────────────────┬────────┐\n",
       "│ head_id    ┆ rel_id                      ┆ tail_id                     ┆ maintain_order ┆ model  │\n",
       "│ ---        ┆ ---                         ┆ ---                         ┆ ---            ┆ ---    │\n",
       "│ str        ┆ str                         ┆ list[str]                   ┆ bool           ┆ str    │\n",
       "╞════════════╪═════════════════════════════╪═════════════════════════════╪════════════════╪════════╡\n",
       "│ /m/089g0h  ┆ /film/film_job/films_with_t ┆ [\"/m/03h4fq7\", \"/m/09hy79\", ┆ true           ┆ TransE │\n",
       "│            ┆ his_c…                      ┆ … \"/…                       ┆                ┆        │\n",
       "│ /m/01whg97 ┆ /people/person/places_lived ┆ [\"/m/0f2v0\", \"/m/0dc95\", …  ┆ true           ┆ TransE │\n",
       "│            ┆ ./peo…                      ┆ \"/m/0…                      ┆                ┆        │\n",
       "│ /m/0jm3b   ┆ /sports/professional_sports ┆ [\"/m/0mbwf\", \"/m/01hr11\", … ┆ true           ┆ TransE │\n",
       "│            ┆ _team…                      ┆ \"/m/…                       ┆                ┆        │\n",
       "│ /m/03h304l ┆ /film/producer/film         ┆ [\"/m/02sfnv\", \"/m/057__d\",  ┆ true           ┆ TransE │\n",
       "│            ┆                             ┆ … \"/m…                      ┆                ┆        │\n",
       "│ /m/037jz   ┆ /influence/influence_node/i ┆ [\"/m/073bb\", \"/m/059y0\", …  ┆ true           ┆ TransE │\n",
       "│            ┆ nflue…                      ┆ \"/m/0…                      ┆                ┆        │\n",
       "└────────────┴─────────────────────────────┴─────────────────────────────┴────────────────┴────────┘"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796, 5)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    combined_df.shape[0] / 4 == combined_df.unique([\"head_id\", \"rel_id\"]).shape[0]\n",
    "), \"Some predictions are not made between all algorithms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export the sample list as well as the parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/home/rogertu/projects/semmed/semmed/data/benchmark_data/FB15k_1000_sampled_test.pkl\",\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    pickle.dump(combined_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.write_parquet(\n",
    "    \"/home/rogertu/projects/semmed/semmed/data/benchmark_data/FB15k_1000_sampled_test_predictions.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
