{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions for WN18RR\n",
    "Generate predictions for WN18RR and store the as a collated dataframe for a set of given predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "import pykeen.datasets\n",
    "import pykeen.models\n",
    "import pykeen.predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import polars as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/datasets/base.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  metadata = torch.load(metadata_path) if metadata_path.is_file() else None\n"
     ]
    }
   ],
   "source": [
    "dataset = pykeen.datasets.get_dataset(dataset=\"WN18RR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TransE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233140/1714231484.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  transe_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load transe model\n",
    "transe_model = pykeen.models.TransE(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=500,\n",
    "    scoring_fct_norm=2,\n",
    "    random_seed=246343514,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "transe_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\n",
    "        \"TransE_WN18RR.pt\"\n",
    "    ),  # accidentally deleted original. rm is sometimes dangerous\n",
    ")\n",
    "# attach state to model\n",
    "transe_model.load_state_dict(transe_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RotatE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233140/2517270343.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rotate_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load rotate model\n",
    "rotate_model = pykeen.models.RotatE(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=250,  # Note this is half the size of the actual embedding dim listed because rotate doubles the embedding dim\n",
    "    random_seed=711022683,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "rotate_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"RotatE_WN18RR.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "rotate_model.load_state_dict(transe_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ComplEx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233140/2939483376.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  complex_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ComplEx model\n",
    "complex_model = pykeen.models.ComplEx(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=500,\n",
    "    random_seed=374523484,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    "    regularizer_kwargs=dict(weight=0.000005, p=3),\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "complex_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"ComplEx_WN18RR.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "complex_model.load_state_dict(complex_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DistMult model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233140/953190981.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  distmult_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load distmult model\n",
    "distmult_model = pykeen.models.DistMult(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=1000,\n",
    "    random_seed=2171371192,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    "    regularizer_kwargs=dict(weight=0.000005, p=3),\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "distmult_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"DistMult_WN18RR.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "distmult_model.load_state_dict(distmult_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on a fixed test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how many nodes and relations are there that we can sample against?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Nodes: 40,559'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of Nodes: {dataset.num_entities:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Relations: 11'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of Relations: {dataset.num_relations:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_label</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>relation_label</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>3826</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>0</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>4475</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>16</td>\n",
       "      <td>4258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>6238</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>612</td>\n",
       "      <td>104868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>6802</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>30</td>\n",
       "      <td>7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>7328</td>\n",
       "      <td>1</td>\n",
       "      <td>_derivationally_related_form</td>\n",
       "      <td>32248</td>\n",
       "      <td>10803193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>40477</td>\n",
       "      <td>15256714</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>22050</td>\n",
       "      <td>5867413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>40516</td>\n",
       "      <td>15274695</td>\n",
       "      <td>1</td>\n",
       "      <td>_derivationally_related_form</td>\n",
       "      <td>4244</td>\n",
       "      <td>779360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>40518</td>\n",
       "      <td>15275598</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>40509</td>\n",
       "      <td>15272029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>40521</td>\n",
       "      <td>15278281</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>40533</td>\n",
       "      <td>15286249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>40552</td>\n",
       "      <td>15298011</td>\n",
       "      <td>9</td>\n",
       "      <td>_synset_domain_topic_of</td>\n",
       "      <td>22456</td>\n",
       "      <td>6128570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2924 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      head_id head_label  relation_id                relation_label  tail_id  \\\n",
       "0          13       3826            3                     _hypernym        0   \n",
       "1          17       4475            3                     _hypernym       16   \n",
       "2          24       6238            3                     _hypernym      612   \n",
       "3          29       6802            3                     _hypernym       30   \n",
       "4          31       7328            1  _derivationally_related_form    32248   \n",
       "...       ...        ...          ...                           ...      ...   \n",
       "2919    40477   15256714            3                     _hypernym    22050   \n",
       "2920    40516   15274695            1  _derivationally_related_form     4244   \n",
       "2921    40518   15275598            3                     _hypernym    40509   \n",
       "2922    40521   15278281            3                     _hypernym    40533   \n",
       "2923    40552   15298011            9       _synset_domain_topic_of    22456   \n",
       "\n",
       "     tail_label  \n",
       "0          1740  \n",
       "1          4258  \n",
       "2        104868  \n",
       "3          7012  \n",
       "4      10803193  \n",
       "...         ...  \n",
       "2919    5867413  \n",
       "2920     779360  \n",
       "2921   15272029  \n",
       "2922   15286249  \n",
       "2923    6128570  \n",
       "\n",
       "[2924 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of testing triples and their correct answers\n",
    "dataset.testing.tensor_to_df(dataset.testing.mapped_triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test triples (at least a small set of it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   13,     3,     0],\n",
       "        [   17,     3,    16],\n",
       "        [   24,     3,   612],\n",
       "        ...,\n",
       "        [40518,     3, 40509],\n",
       "        [40521,     3, 40533],\n",
       "        [40552,     9, 22456]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how the tensor looks\n",
    "dataset.testing.mapped_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2924, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the tensor\n",
    "dataset.testing.mapped_triples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1000 random indices to slice the testing triples\n",
    "random_ind = np.random.choice(\n",
    "    np.array(range(0, dataset.testing.mapped_triples.shape[0])), 1000, replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sliced tensor of testing triples\n",
    "dataset.testing.mapped_triples[random_ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists of triples\n",
    "# [[head, relation, tail], ...]\n",
    "test_set = dataset.testing.mapped_triples[random_ind].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get top 1000 predictions in our random sample.\n",
    "* May or may not be exactly 1000 unique entity/relation combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write afunction to make predictions on the models\n",
    "def get_top_tail_predictions(model, test_set, dataset, k=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a model, and a test set, return the top predictions for the test set\n",
    "\n",
    "    model: pykeen.models.Model\n",
    "    test_set: list of lists of triples [[head, relation, tail], ...]\n",
    "    dataset: pykeen.datasets.dataset.TriplesFactory\n",
    "    k: int, number of top predictions to return\n",
    "\n",
    "    returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # create dictionaries for entities and relations\n",
    "    id2entity = {v: k for k, v in dataset.entity_to_id.items()}\n",
    "    id2relation = {v: k for k, v in dataset.relation_to_id.items()}\n",
    "\n",
    "    # get the top predictions for the first entry in the test set\n",
    "    res_ls = []\n",
    "    for i in test_set:\n",
    "        # generate predictions and cast to a polars dataframe\n",
    "        polars_df = pl.DataFrame(\n",
    "            pykeen.predict.predict_target(\n",
    "                model=model, triples_factory=dataset, head=i[0], relation=i[1]\n",
    "            ).df\n",
    "        )\n",
    "        # sort the predictions by score, add head and relation ids\n",
    "        polars_df = polars_df.with_columns(\n",
    "            pl.col(\"score\").sort(descending=True),\n",
    "            head_id=i[0],  # assign head_id\n",
    "            rel_id=i[1],  # assign relation_id\n",
    "        )\n",
    "        res_ls.append(polars_df)\n",
    "\n",
    "    # rename entities in head/tail/relation from ids to actual names\n",
    "    # collapse tail_ids to a single row based on head and relation_ids\n",
    "    res_df = (\n",
    "        pl.concat(res_ls)\n",
    "        .with_columns(\n",
    "            # rename entities in head/tail/relation from ids to actual names\n",
    "            pl.col(\"tail_id\").cast(pl.String).replace(id2entity),\n",
    "            pl.col(\"head_id\").cast(pl.String).replace(id2entity),\n",
    "            pl.col(\"rel_id\").cast(pl.String).replace(id2relation),\n",
    "        )\n",
    "        .unique([\"head_id\", \"rel_id\", \"tail_id\"])\n",
    "        .group_by([\"head_id\", \"rel_id\"])\n",
    "        .agg(\"tail_id\", maintain_order=True)\n",
    "    )\n",
    "\n",
    "    # return top k predictions\n",
    "    if k > 0:\n",
    "        res_df = res_df.with_columns(pl.col(\"tail_id\").list.head(k))\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transe_df = get_top_tail_predictions(transe_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "distumult_df = get_top_tail_predictions(distmult_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_df = get_top_tail_predictions(complex_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_df = get_top_tail_predictions(rotate_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add column name identifier to each dataframe.\n",
    "* then stack them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transe_df = transe_df.with_columns(model=pl.lit(\"TransE\"))\n",
    "distumult_df = distumult_df.with_columns(model=pl.lit(\"DistMult\"))\n",
    "complex_df = complex_df.with_columns(model=pl.lit(\"ComplEx\"))\n",
    "rotate_df = rotate_df.with_columns(model=pl.lit(\"RotatE\"))\n",
    "\n",
    "# combine the results\n",
    "combined_df = pl.concat([transe_df, distumult_df, complex_df, rotate_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>head_id</th><th>rel_id</th><th>tail_id</th><th>maintain_order</th><th>model</th></tr><tr><td>str</td><td>str</td><td>list[str]</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;1575401&quot;</td><td>&quot;_hypernym&quot;</td><td>[&quot;24264&quot;, &quot;426928&quot;, … &quot;6805297&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;12723610&quot;</td><td>&quot;_hypernym&quot;</td><td>[&quot;14034177&quot;, &quot;7480068&quot;, … &quot;14440875&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;508952&quot;</td><td>&quot;_hypernym&quot;</td><td>[&quot;2210855&quot;, &quot;4623612&quot;, … &quot;3196990&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;9767197&quot;</td><td>&quot;_derivationall…</td><td>[&quot;5020358&quot;, &quot;1225461&quot;, … &quot;7255027&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;10826352&quot;</td><td>&quot;_instance_hype…</td><td>[&quot;8177958&quot;, &quot;730984&quot;, … &quot;1749320&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────┬──────────────────────────────┬───────────────────────────┬────────────────┬────────┐\n",
       "│ head_id  ┆ rel_id                       ┆ tail_id                   ┆ maintain_order ┆ model  │\n",
       "│ ---      ┆ ---                          ┆ ---                       ┆ ---            ┆ ---    │\n",
       "│ str      ┆ str                          ┆ list[str]                 ┆ bool           ┆ str    │\n",
       "╞══════════╪══════════════════════════════╪═══════════════════════════╪════════════════╪════════╡\n",
       "│ 1575401  ┆ _hypernym                    ┆ [\"24264\", \"426928\", …     ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"6805297\"]                ┆                ┆        │\n",
       "│ 12723610 ┆ _hypernym                    ┆ [\"14034177\", \"7480068\", … ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"14440…                   ┆                ┆        │\n",
       "│ 508952   ┆ _hypernym                    ┆ [\"2210855\", \"4623612\", …  ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"319699…                  ┆                ┆        │\n",
       "│ 9767197  ┆ _derivationally_related_form ┆ [\"5020358\", \"1225461\", …  ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"725502…                  ┆                ┆        │\n",
       "│ 10826352 ┆ _instance_hypernym           ┆ [\"8177958\", \"730984\", …   ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"1749320…                 ┆                ┆        │\n",
       "└──────────┴──────────────────────────────┴───────────────────────────┴────────────────┴────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3924, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    combined_df.shape[0] / 4 == combined_df.unique([\"head_id\", \"rel_id\"]).shape[0]\n",
    "), \"Some predictions are not made between all algorithms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export the sample list as well as the parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/home/rogertu/projects/semmed/semmed/data/benchmark_data/WN18RR_1000_sampled_test.pkl\",\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    pickle.dump(combined_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.write_parquet(\n",
    "    \"/home/rogertu/projects/semmed/semmed/data/benchmark_data/WN18RR_1000_sampled_test_predictions.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
