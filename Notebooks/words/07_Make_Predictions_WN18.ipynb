{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions for WN18\n",
    "Generate predictions for WN18 and store the as a collated dataframe for a set of given predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "import pykeen.datasets\n",
    "import pykeen.models\n",
    "import pykeen.predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import polars as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/datasets/base.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  metadata = torch.load(metadata_path) if metadata_path.is_file() else None\n"
     ]
    }
   ],
   "source": [
    "dataset = pykeen.datasets.get_dataset(dataset=\"WN18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TransE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228982/3608602754.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  transe_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load transe model\n",
    "transe_model = pykeen.models.TransE(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=500,\n",
    "    scoring_fct_norm=2,\n",
    "    random_seed=2107241829,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "transe_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\n",
    "        \"TransE_WN18_2.pt\"\n",
    "    ),  # accidentally deleted original. rm is sometimes dangerous\n",
    ")\n",
    "# attach state to model\n",
    "transe_model.load_state_dict(transe_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RotatE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228982/165234142.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rotate_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load rotate model\n",
    "rotate_model = pykeen.models.RotatE(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=250,  # Note this is half the size of the actual embedding dim listed because rotate doubles the embedding dim\n",
    "    random_seed=2382073919,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "rotate_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"RotatE_WN18.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "rotate_model.load_state_dict(transe_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ComplEx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228982/2070738479.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  complex_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ComplEx model\n",
    "complex_model = pykeen.models.ComplEx(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=500,\n",
    "    random_seed=2152372825,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    "    regularizer_kwargs=dict(weight=0.00001, p=3),\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "complex_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"ComplEx_WN18.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "complex_model.load_state_dict(complex_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DistMult model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228982/2654902952.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  distmult_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load distmult model\n",
    "distmult_model = pykeen.models.DistMult(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=1000,\n",
    "    random_seed=1191075500,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    "    regularizer_kwargs=dict(weight=0.00001, p=3),\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "distmult_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"DistMult_WN18.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "distmult_model.load_state_dict(distmult_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on a fixed test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how many nodes and relations are there that we can sample against?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Nodes: 40,943'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of Nodes: {dataset.num_entities:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Relations: 18'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of Relations: {dataset.num_relations:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_label</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>relation_label</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>3826</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>0</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>4475</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>16</td>\n",
       "      <td>4258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>6238</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>618</td>\n",
       "      <td>104868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>6802</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>30</td>\n",
       "      <td>7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>7328</td>\n",
       "      <td>1</td>\n",
       "      <td>_derivationally_related_form</td>\n",
       "      <td>32527</td>\n",
       "      <td>10803193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>40901</td>\n",
       "      <td>15275598</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>40892</td>\n",
       "      <td>15272029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>40904</td>\n",
       "      <td>15278281</td>\n",
       "      <td>3</td>\n",
       "      <td>_hypernym</td>\n",
       "      <td>40917</td>\n",
       "      <td>15286249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>40907</td>\n",
       "      <td>15279596</td>\n",
       "      <td>12</td>\n",
       "      <td>_part_of</td>\n",
       "      <td>40908</td>\n",
       "      <td>15279957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>40916</td>\n",
       "      <td>15286042</td>\n",
       "      <td>12</td>\n",
       "      <td>_part_of</td>\n",
       "      <td>2964</td>\n",
       "      <td>543233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>40936</td>\n",
       "      <td>15298011</td>\n",
       "      <td>15</td>\n",
       "      <td>_synset_domain_topic_of</td>\n",
       "      <td>22643</td>\n",
       "      <td>6128570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      head_id head_label  relation_id                relation_label  tail_id  \\\n",
       "0          13       3826            3                     _hypernym        0   \n",
       "1          17       4475            3                     _hypernym       16   \n",
       "2          24       6238            3                     _hypernym      618   \n",
       "3          29       6802            3                     _hypernym       30   \n",
       "4          31       7328            1  _derivationally_related_form    32527   \n",
       "...       ...        ...          ...                           ...      ...   \n",
       "4995    40901   15275598            3                     _hypernym    40892   \n",
       "4996    40904   15278281            3                     _hypernym    40917   \n",
       "4997    40907   15279596           12                      _part_of    40908   \n",
       "4998    40916   15286042           12                      _part_of     2964   \n",
       "4999    40936   15298011           15       _synset_domain_topic_of    22643   \n",
       "\n",
       "     tail_label  \n",
       "0          1740  \n",
       "1          4258  \n",
       "2        104868  \n",
       "3          7012  \n",
       "4      10803193  \n",
       "...         ...  \n",
       "4995   15272029  \n",
       "4996   15286249  \n",
       "4997   15279957  \n",
       "4998     543233  \n",
       "4999    6128570  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of testing triples and their correct answers\n",
    "dataset.testing.tensor_to_df(dataset.testing.mapped_triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test triples (at least a small set of it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   13,     3,     0],\n",
       "        [   17,     3,    16],\n",
       "        [   24,     3,   618],\n",
       "        ...,\n",
       "        [40907,    12, 40908],\n",
       "        [40916,    12,  2964],\n",
       "        [40936,    15, 22643]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how the tensor looks\n",
    "dataset.testing.mapped_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the tensor\n",
    "dataset.testing.mapped_triples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1000 random indices to slice the testing triples\n",
    "random_ind = np.random.choice(\n",
    "    np.array(range(0, dataset.testing.mapped_triples.shape[0])), 1000, replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sliced tensor of testing triples\n",
    "dataset.testing.mapped_triples[random_ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists of triples\n",
    "# [[head, relation, tail], ...]\n",
    "test_set = dataset.testing.mapped_triples[random_ind].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get top 1000 predictions in our random sample.\n",
    "* May or may not be exactly 1000 unique entity/relation combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write afunction to make predictions on the models\n",
    "def get_top_tail_predictions(model, test_set, dataset, k=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a model, and a test set, return the top predictions for the test set\n",
    "\n",
    "    model: pykeen.models.Model\n",
    "    test_set: list of lists of triples [[head, relation, tail], ...]\n",
    "    dataset: pykeen.datasets.dataset.TriplesFactory\n",
    "    k: int, number of top predictions to return\n",
    "\n",
    "    returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # create dictionaries for entities and relations\n",
    "    id2entity = {v: k for k, v in dataset.entity_to_id.items()}\n",
    "    id2relation = {v: k for k, v in dataset.relation_to_id.items()}\n",
    "\n",
    "    # get the top predictions for the first entry in the test set\n",
    "    res_ls = []\n",
    "    for i in test_set:\n",
    "        # generate predictions and cast to a polars dataframe\n",
    "        polars_df = pl.DataFrame(\n",
    "            pykeen.predict.predict_target(\n",
    "                model=model, triples_factory=dataset, head=i[0], relation=i[1]\n",
    "            ).df\n",
    "        )\n",
    "        # sort the predictions by score, add head and relation ids\n",
    "        polars_df = polars_df.with_columns(\n",
    "            pl.col(\"score\").sort(descending=True),\n",
    "            head_id=i[0],  # assign head_id\n",
    "            rel_id=i[1],  # assign relation_id\n",
    "        )\n",
    "        res_ls.append(polars_df)\n",
    "\n",
    "    # rename entities in head/tail/relation from ids to actual names\n",
    "    # collapse tail_ids to a single row based on head and relation_ids\n",
    "    res_df = (\n",
    "        pl.concat(res_ls)\n",
    "        .with_columns(\n",
    "            # rename entities in head/tail/relation from ids to actual names\n",
    "            pl.col(\"tail_id\").cast(pl.String).replace(id2entity),\n",
    "            pl.col(\"head_id\").cast(pl.String).replace(id2entity),\n",
    "            pl.col(\"rel_id\").cast(pl.String).replace(id2relation),\n",
    "        )\n",
    "        .unique([\"head_id\", \"rel_id\", \"tail_id\"])\n",
    "        .group_by([\"head_id\", \"rel_id\"])\n",
    "        .agg(\"tail_id\", maintain_order=True)\n",
    "    )\n",
    "\n",
    "    # return top k predictions\n",
    "    if k > 0:\n",
    "        res_df = res_df.with_columns(pl.col(\"tail_id\").list.head(k))\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transe_df = get_top_tail_predictions(transe_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "distumult_df = get_top_tail_predictions(distmult_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_df = get_top_tail_predictions(complex_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_df = get_top_tail_predictions(rotate_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add column name identifier to each dataframe.\n",
    "* then stack them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transe_df = transe_df.with_columns(model=pl.lit(\"TransE\"))\n",
    "distumult_df = distumult_df.with_columns(model=pl.lit(\"DistMult\"))\n",
    "complex_df = complex_df.with_columns(model=pl.lit(\"ComplEx\"))\n",
    "rotate_df = rotate_df.with_columns(model=pl.lit(\"RotatE\"))\n",
    "\n",
    "# combine the results\n",
    "combined_df = pl.concat([transe_df, distumult_df, complex_df, rotate_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>head_id</th><th>rel_id</th><th>tail_id</th><th>maintain_order</th><th>model</th></tr><tr><td>str</td><td>str</td><td>list[str]</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;12102133&quot;</td><td>&quot;_hyponym&quot;</td><td>[&quot;659349&quot;, &quot;1159964&quot;, … &quot;5289057&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;12508077&quot;</td><td>&quot;_hypernym&quot;</td><td>[&quot;5833840&quot;, &quot;2441022&quot;, … &quot;10278128&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;2950482&quot;</td><td>&quot;_hypernym&quot;</td><td>[&quot;2016523&quot;, &quot;9815790&quot;, … &quot;12505563&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;10271216&quot;</td><td>&quot;_derivationall…</td><td>[&quot;1344293&quot;, &quot;1500082&quot;, … &quot;8304895&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;367976&quot;</td><td>&quot;_hyponym&quot;</td><td>[&quot;5722208&quot;, &quot;680485&quot;, … &quot;1902783&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────┬──────────────────────────────┬──────────────────────────┬────────────────┬────────┐\n",
       "│ head_id  ┆ rel_id                       ┆ tail_id                  ┆ maintain_order ┆ model  │\n",
       "│ ---      ┆ ---                          ┆ ---                      ┆ ---            ┆ ---    │\n",
       "│ str      ┆ str                          ┆ list[str]                ┆ bool           ┆ str    │\n",
       "╞══════════╪══════════════════════════════╪══════════════════════════╪════════════════╪════════╡\n",
       "│ 12102133 ┆ _hyponym                     ┆ [\"659349\", \"1159964\", …  ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"5289057…                ┆                ┆        │\n",
       "│ 12508077 ┆ _hypernym                    ┆ [\"5833840\", \"2441022\", … ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"102781…                 ┆                ┆        │\n",
       "│ 2950482  ┆ _hypernym                    ┆ [\"2016523\", \"9815790\", … ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"125055…                 ┆                ┆        │\n",
       "│ 10271216 ┆ _derivationally_related_form ┆ [\"1344293\", \"1500082\", … ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"830489…                 ┆                ┆        │\n",
       "│ 367976   ┆ _hyponym                     ┆ [\"5722208\", \"680485\", …  ┆ true           ┆ TransE │\n",
       "│          ┆                              ┆ \"1902783…                ┆                ┆        │\n",
       "└──────────┴──────────────────────────────┴──────────────────────────┴────────────────┴────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3880, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    combined_df.shape[0] / 4 == combined_df.unique([\"head_id\", \"rel_id\"]).shape[0]\n",
    "), \"Some predictions are not made between all algorithms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export the sample list as well as the parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/home/rogertu/projects/semmed/semmed/data/benchmark_data/WN18_1000_sampled_test.pkl\",\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    pickle.dump(combined_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.write_parquet(\n",
    "    \"/home/rogertu/projects/semmed/semmed/data/benchmark_data/WN18_1000_sampled_test_predictions.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
