{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions for FB15k-237\n",
    "Generate predictions for FB15k-237 and store the as a collated dataframe for a set of given predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "import pykeen.datasets\n",
    "import pykeen.models\n",
    "import pykeen.predict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import polars as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/triples/triples_factory.py:763: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = dict(torch.load(path.joinpath(cls.base_file_name)))\n",
      "/home/rogertu/miniforge3/envs/mini_semmed/lib/python3.12/site-packages/pykeen/datasets/base.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  metadata = torch.load(metadata_path) if metadata_path.is_file() else None\n"
     ]
    }
   ],
   "source": [
    "dataset = pykeen.datasets.get_dataset(dataset=\"FB15k-237\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TransE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225966/2687486448.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  transe_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load transe model\n",
    "transe_model = pykeen.models.TransE(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=1000,\n",
    "    scoring_fct_norm=2,\n",
    "    random_seed=389976964,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "transe_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\n",
    "        \"TransE_FB15k237.pt\"\n",
    "    ),  # accidentally deleted original. rm is sometimes dangerous\n",
    ")\n",
    "# attach state to model\n",
    "transe_model.load_state_dict(transe_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load RotatE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225966/570812159.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rotate_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load rotate model\n",
    "rotate_model = pykeen.models.RotatE(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=500,  # Note this is half the size of the actual embedding dim listed because rotate doubles the embedding dim\n",
    "    random_seed=476543017,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "rotate_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"RotatE_FB15k237.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "rotate_model.load_state_dict(transe_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ComplEx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225966/2332031850.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  complex_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load rotate model\n",
    "complex_model = pykeen.models.ComplEx(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=1000,\n",
    "    random_seed=3951611747,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    "    regularizer_kwargs=dict(weight=0.00001, p=3),\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "complex_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"ComplEx_FB15k237.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "complex_model.load_state_dict(complex_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DistMult model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225966/3963687679.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  distmult_chkpt = torch.load(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load rotate model\n",
    "distmult_model = pykeen.models.DistMult(\n",
    "    triples_factory=dataset.training,\n",
    "    embedding_dim=2000,\n",
    "    random_seed=708788984,  # use same seed as training otherwise model and chkpt train/test split will be different\n",
    "    regularizer_kwargs=dict(weight=0.00001, p=3),\n",
    ")\n",
    "\n",
    "# load chkpt\n",
    "distmult_chkpt = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"DistMult_FB15k237.pt\"),\n",
    ")\n",
    "# attach state to model\n",
    "distmult_model.load_state_dict(distmult_chkpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on a fixed test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how many nodes and relations are there that we can sample against?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Nodes: 14,505'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of Nodes: {dataset.num_entities:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Relations: 237'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of Relations: {dataset.num_relations:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_label</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>relation_label</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>/m/0102t4</td>\n",
       "      <td>131</td>\n",
       "      <td>/location/location/time_zones</td>\n",
       "      <td>4267</td>\n",
       "      <td>/m/02fqwt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>/m/0105y2</td>\n",
       "      <td>131</td>\n",
       "      <td>/location/location/time_zones</td>\n",
       "      <td>4267</td>\n",
       "      <td>/m/02fqwt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>/m/0106dv</td>\n",
       "      <td>126</td>\n",
       "      <td>/location/hud_county_place/place</td>\n",
       "      <td>5</td>\n",
       "      <td>/m/0106dv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>/m/0109vk</td>\n",
       "      <td>131</td>\n",
       "      <td>/location/location/time_zones</td>\n",
       "      <td>4267</td>\n",
       "      <td>/m/02fqwt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>/m/010bxh</td>\n",
       "      <td>131</td>\n",
       "      <td>/location/location/time_zones</td>\n",
       "      <td>4267</td>\n",
       "      <td>/m/02fqwt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20433</th>\n",
       "      <td>14490</td>\n",
       "      <td>/m/0zcbl</td>\n",
       "      <td>68</td>\n",
       "      <td>/film/actor/film./film/performance/film</td>\n",
       "      <td>9047</td>\n",
       "      <td>/m/06lpmt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20434</th>\n",
       "      <td>14490</td>\n",
       "      <td>/m/0zcbl</td>\n",
       "      <td>68</td>\n",
       "      <td>/film/actor/film./film/performance/film</td>\n",
       "      <td>9703</td>\n",
       "      <td>/m/07nt8p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20435</th>\n",
       "      <td>14490</td>\n",
       "      <td>/m/0zcbl</td>\n",
       "      <td>190</td>\n",
       "      <td>/people/person/places_lived./people/place_live...</td>\n",
       "      <td>11603</td>\n",
       "      <td>/m/0d9jr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20436</th>\n",
       "      <td>14499</td>\n",
       "      <td>/m/0zpfy</td>\n",
       "      <td>50</td>\n",
       "      <td>/common/topic/webpage./common/webpage/category</td>\n",
       "      <td>10165</td>\n",
       "      <td>/m/08mbj5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20437</th>\n",
       "      <td>14501</td>\n",
       "      <td>/m/0zqq8</td>\n",
       "      <td>131</td>\n",
       "      <td>/location/location/time_zones</td>\n",
       "      <td>4370</td>\n",
       "      <td>/m/02hcv8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20438 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       head_id head_label  relation_id  \\\n",
       "0            2  /m/0102t4          131   \n",
       "1            4  /m/0105y2          131   \n",
       "2            5  /m/0106dv          126   \n",
       "3            7  /m/0109vk          131   \n",
       "4            9  /m/010bxh          131   \n",
       "...        ...        ...          ...   \n",
       "20433    14490   /m/0zcbl           68   \n",
       "20434    14490   /m/0zcbl           68   \n",
       "20435    14490   /m/0zcbl          190   \n",
       "20436    14499   /m/0zpfy           50   \n",
       "20437    14501   /m/0zqq8          131   \n",
       "\n",
       "                                          relation_label  tail_id  tail_label  \n",
       "0                          /location/location/time_zones     4267   /m/02fqwt  \n",
       "1                          /location/location/time_zones     4267   /m/02fqwt  \n",
       "2                       /location/hud_county_place/place        5   /m/0106dv  \n",
       "3                          /location/location/time_zones     4267   /m/02fqwt  \n",
       "4                          /location/location/time_zones     4267   /m/02fqwt  \n",
       "...                                                  ...      ...         ...  \n",
       "20433            /film/actor/film./film/performance/film     9047   /m/06lpmt  \n",
       "20434            /film/actor/film./film/performance/film     9703   /m/07nt8p  \n",
       "20435  /people/person/places_lived./people/place_live...    11603    /m/0d9jr  \n",
       "20436     /common/topic/webpage./common/webpage/category    10165  /m/08mbj5d  \n",
       "20437                      /location/location/time_zones     4370   /m/02hcv8  \n",
       "\n",
       "[20438 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of testing triples and their correct answers\n",
    "dataset.testing.tensor_to_df(dataset.testing.mapped_triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get test triples (at least a small set of it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,   131,  4267],\n",
       "        [    4,   131,  4267],\n",
       "        [    5,   126,     5],\n",
       "        ...,\n",
       "        [14490,   190, 11603],\n",
       "        [14499,    50, 10165],\n",
       "        [14501,   131,  4370]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how the tensor looks\n",
    "dataset.testing.mapped_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20438, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the tensor\n",
    "dataset.testing.mapped_triples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1000 random indices to slice the testing triples\n",
    "random_ind = np.random.choice(\n",
    "    np.array(range(0, dataset.testing.mapped_triples.shape[0])), 1000, replace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sliced tensor of testing triples\n",
    "dataset.testing.mapped_triples[random_ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists of triples\n",
    "# [[head, relation, tail], ...]\n",
    "test_set = dataset.testing.mapped_triples[random_ind].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get top 1000 predictions in our random sample.\n",
    "* May or may not be exactly 1000 unique entity/relation combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write afunction to make predictions on the models\n",
    "def get_top_tail_predictions(model, test_set, dataset, k=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a model, and a test set, return the top predictions for the test set\n",
    "\n",
    "    model: pykeen.models.Model\n",
    "    test_set: list of lists of triples [[head, relation, tail], ...]\n",
    "    dataset: pykeen.datasets.dataset.TriplesFactory\n",
    "    k: int, number of top predictions to return\n",
    "\n",
    "    returns: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # create dictionaries for entities and relations\n",
    "    id2entity = {v: k for k, v in dataset.entity_to_id.items()}\n",
    "    id2relation = {v: k for k, v in dataset.relation_to_id.items()}\n",
    "\n",
    "    # get the top predictions for the first entry in the test set\n",
    "    res_ls = []\n",
    "    for i in test_set:\n",
    "        # generate predictions and cast to a polars dataframe\n",
    "        polars_df = pl.DataFrame(\n",
    "            pykeen.predict.predict_target(\n",
    "                model=model, triples_factory=dataset, head=i[0], relation=i[1]\n",
    "            ).df\n",
    "        )\n",
    "        # sort the predictions by score, add head and relation ids\n",
    "        polars_df = polars_df.with_columns(\n",
    "            pl.col(\"score\").sort(descending=True),\n",
    "            head_id=i[0],  # assign head_id\n",
    "            rel_id=i[1],  # assign relation_id\n",
    "        )\n",
    "        res_ls.append(polars_df)\n",
    "\n",
    "    # rename entities in head/tail/relation from ids to actual names\n",
    "    # collapse tail_ids to a single row based on head and relation_ids\n",
    "    res_df = (\n",
    "        pl.concat(res_ls)\n",
    "        .with_columns(\n",
    "            # rename entities in head/tail/relation from ids to actual names\n",
    "            pl.col(\"tail_id\").cast(pl.String).replace(id2entity),\n",
    "            pl.col(\"head_id\").cast(pl.String).replace(id2entity),\n",
    "            pl.col(\"rel_id\").cast(pl.String).replace(id2relation),\n",
    "        )\n",
    "        .unique([\"head_id\", \"rel_id\", \"tail_id\"])\n",
    "        .group_by([\"head_id\", \"rel_id\"])\n",
    "        .agg(\"tail_id\", maintain_order=True)\n",
    "    )\n",
    "\n",
    "    # return top k predictions\n",
    "    if k > 0:\n",
    "        res_df = res_df.with_columns(pl.col(\"tail_id\").list.head(k))\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transe_df = get_top_tail_predictions(transe_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "distumult_df = get_top_tail_predictions(distmult_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_df = get_top_tail_predictions(complex_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_df = get_top_tail_predictions(rotate_model, test_set, dataset, k=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add column name identifier to each dataframe.\n",
    "* then stack them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transe_df = transe_df.with_columns(model=pl.lit(\"TransE\"))\n",
    "distumult_df = distumult_df.with_columns(model=pl.lit(\"DistMult\"))\n",
    "complex_df = complex_df.with_columns(model=pl.lit(\"ComplEx\"))\n",
    "rotate_df = rotate_df.with_columns(model=pl.lit(\"RotatE\"))\n",
    "\n",
    "# combine the results\n",
    "combined_df = pl.concat([transe_df, distumult_df, complex_df, rotate_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>head_id</th><th>rel_id</th><th>tail_id</th><th>maintain_order</th><th>model</th></tr><tr><td>str</td><td>str</td><td>list[str]</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;/m/0770cd&quot;</td><td>&quot;/music/artist/…</td><td>[&quot;/m/014zz1&quot;, &quot;/m/07v64s&quot;, … &quot;/m/0gclb&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;/m/07_m9_&quot;</td><td>&quot;/people/person…</td><td>[&quot;/m/0d05w3&quot;, &quot;/m/015fr&quot;, … &quot;/m/021s9n&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;/m/058kqy&quot;</td><td>&quot;/base/schemast…</td><td>[&quot;/m/07brj&quot;, &quot;/m/02k856&quot;, … &quot;/m/03jqw5&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;/m/07tg4&quot;</td><td>&quot;/education/edu…</td><td>[&quot;/m/0crqcc&quot;, &quot;/m/01cpqk&quot;, … &quot;/m/0lpfh&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr><tr><td>&quot;/m/0dcz8_&quot;</td><td>&quot;/film/film/gen…</td><td>[&quot;/m/02js9&quot;, &quot;/m/0c4xc&quot;, … &quot;/m/01_f_5&quot;]</td><td>true</td><td>&quot;TransE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌───────────┬──────────────────────────────┬─────────────────────────────┬────────────────┬────────┐\n",
       "│ head_id   ┆ rel_id                       ┆ tail_id                     ┆ maintain_order ┆ model  │\n",
       "│ ---       ┆ ---                          ┆ ---                         ┆ ---            ┆ ---    │\n",
       "│ str       ┆ str                          ┆ list[str]                   ┆ bool           ┆ str    │\n",
       "╞═══════════╪══════════════════════════════╪═════════════════════════════╪════════════════╪════════╡\n",
       "│ /m/0770cd ┆ /music/artist/track_contribu ┆ [\"/m/014zz1\", \"/m/07v64s\",  ┆ true           ┆ TransE │\n",
       "│           ┆ tion…                        ┆ … \"/m…                      ┆                ┆        │\n",
       "│ /m/07_m9_ ┆ /people/person/nationality   ┆ [\"/m/0d05w3\", \"/m/015fr\", … ┆ true           ┆ TransE │\n",
       "│           ┆                              ┆ \"/m/…                       ┆                ┆        │\n",
       "│ /m/058kqy ┆ /base/schemastaging/person_e ┆ [\"/m/07brj\", \"/m/02k856\", … ┆ true           ┆ TransE │\n",
       "│           ┆ xtra…                        ┆ \"/m/…                       ┆                ┆        │\n",
       "│ /m/07tg4  ┆ /education/educational_insti ┆ [\"/m/0crqcc\", \"/m/01cpqk\",  ┆ true           ┆ TransE │\n",
       "│           ┆ tuti…                        ┆ … \"/m…                      ┆                ┆        │\n",
       "│ /m/0dcz8_ ┆ /film/film/genre             ┆ [\"/m/02js9\", \"/m/0c4xc\", …  ┆ true           ┆ TransE │\n",
       "│           ┆                              ┆ \"/m/0…                      ┆                ┆        │\n",
       "└───────────┴──────────────────────────────┴─────────────────────────────┴────────────────┴────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3792, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    combined_df.shape[0] / 4 == combined_df.unique([\"head_id\", \"rel_id\"]).shape[0]\n",
    "), \"Some predictions are not made between all algorithms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export the sample list as well as the parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/home/rogertu/projects/semmed/semmed/data/benchmark_data/FB15k237_1000_sampled_test.pkl\",\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    pickle.dump(combined_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.write_parquet(\n",
    "    \"/home/rogertu/projects/semmed/semmed/data/benchmark_data/FB15k237_1000_sampled_test_predictions.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
