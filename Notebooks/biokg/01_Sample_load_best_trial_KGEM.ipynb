{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Knowledge Graph Embedding predictions overview\n",
    "* [Rivas et al](https://academic.oup.com/bib/article/23/6/bbac481/6831005) ran KGEM hyperparameter optimizations on a miniturized BioKG and OpenBiolink (OBL) dataset\n",
    "* this notebook aims to highlight the general process of extracting and running the generated models in the paper\n",
    "* there are three sections: training a model using the optimized parameters, loading a model and making predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model using the optimized parameters\n",
    "\n",
    "* If you want to train your own model using pykeen, and you have already run hyperparameter optimizations, see the following code cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in optimized parameters for TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the downloaded hyperparameters from rivas et al paper\n",
    "with open(\n",
    "    \"/home/rogertu/projects/KGEM/models/biokg/transe/0000_user_data_transe/best_pipeline/pipeline_config.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'_stopper_comment': 'While the original config had 300, early stopping will now switch it to 110',\n",
       "  '_stopper_kwargs_removed_comment': \"stopper_kwargs config removed after HPO: {'frequency': 10, 'patience': 3, 'relative_delta': 0.002}\",\n",
       "  'best_trial_evaluation': 0.14579331540530158,\n",
       "  'best_trial_number': 17,\n",
       "  'git_hash': 'UNHASHED',\n",
       "  'version': '1.8.0'},\n",
       " 'pipeline': {'dataset_kwargs': {'create_inverse_triples': False},\n",
       "  'evaluation_kwargs': {'batch_size': None},\n",
       "  'evaluator': 'rankbased',\n",
       "  'evaluator_kwargs': {'filtered': True},\n",
       "  'filter_validation_when_testing': True,\n",
       "  'loss': 'bcewithlogits',\n",
       "  'model': 'transe',\n",
       "  'model_kwargs': {'embedding_dim': 48, 'scoring_fct_norm': 1},\n",
       "  'optimizer': 'adam',\n",
       "  'optimizer_kwargs': {'lr': 0.004722695778102846},\n",
       "  'testing': '/opt/ml/processing/input/test.tsv',\n",
       "  'training': '/opt/ml/processing/input/train.tsv',\n",
       "  'training_kwargs': {'batch_size': 1232, 'num_epochs': 110},\n",
       "  'training_loop': 'lcwa',\n",
       "  'validation': '/opt/ml/processing/input/val.tsv'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of what their configs look like. JSON of metadata and pipeline values\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just want the pipeline\n",
    "pipeline_configs = configs[\"pipeline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add checkpoint name so we can load the model later\n",
    "pipeline_configs[\"training_kwargs\"].update(\n",
    "    {\"checkpoint_name\": \"biokg_transe_checkpoint.pt\", \"checkpoint_frequency\": 1}\n",
    ")\n",
    "# update train/test/valid paths\n",
    "\n",
    "biokg_base = \"/home/rogertu/projects/KGEM/data/biokg\"\n",
    "pipeline_configs.update(\n",
    "    {\n",
    "        \"training\": os.path.join(biokg_base, \"train.tsv\"),\n",
    "        \"testing\": os.path.join(biokg_base, \"test.tsv\"),\n",
    "        \"validation\": os.path.join(biokg_base, \"valid.tsv\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_kwargs': {'create_inverse_triples': False},\n",
       " 'evaluation_kwargs': {'batch_size': None},\n",
       " 'evaluator': 'rankbased',\n",
       " 'evaluator_kwargs': {'filtered': True},\n",
       " 'filter_validation_when_testing': True,\n",
       " 'loss': 'bcewithlogits',\n",
       " 'model': 'transe',\n",
       " 'model_kwargs': {'embedding_dim': 48, 'scoring_fct_norm': 1},\n",
       " 'optimizer': 'adam',\n",
       " 'optimizer_kwargs': {'lr': 0.004722695778102846},\n",
       " 'testing': '/home/rogertu/projects/KGEM/data/biokg/test.tsv',\n",
       " 'training': '/home/rogertu/projects/KGEM/data/biokg/train.tsv',\n",
       " 'training_kwargs': {'batch_size': 1232,\n",
       "  'num_epochs': 100,\n",
       "  'checkpoint_name': 'biokg_transe_checkpoint.pt',\n",
       "  'checkpoint_frequency': 5},\n",
       " 'training_loop': 'lcwa',\n",
       " 'validation': '/home/rogertu/projects/KGEM/data/biokg/valid.tsv'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check new configs\n",
    "pipeline_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model using the predefined configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs the pykeen training pipeline to build a model for the mini-biokg dataset (as seen in the rivas paper)\n",
    "res = pipeline(**pipeline_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prior trained model\n",
    "* the following is a template of how to run predictions for already trained models\n",
    "* not guaranteed to run, because you need to have the models already created. The code was copied from a different notebook that ran\n",
    "* two steps: load the dataset/model, and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "train = TriplesFactory.from_path(os.path.join(biokg_base, \"train.tsv\"), delimiter=\"\\t\")\n",
    "test = TriplesFactory.from_path(os.path.join(biokg_base, \"test.tsv\"), delimiter=\"\\t\")\n",
    "valid = TriplesFactory.from_path(os.path.join(biokg_base, \"valid.tsv\"), delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model parameters\n",
    "pykeen_model = pykeen.models.TransE(  # pick the model that you had trained\n",
    "    triples_factory=train,\n",
    "    # model configuration\n",
    "    embedding_dim=pipeline_configs[\"model_kwargs\"][\"embedding_dim\"],\n",
    "    scoring_fct_norm=pipeline_configs[\"model_kwargs\"][\"scoring_fct_norm\"],\n",
    ")\n",
    "\n",
    "# load the checkpoint. This directory for me was at ~./data/pykeen/checkpoints\n",
    "model_checkpoint = torch.load(\n",
    "    pykeen.constants.PYKEEN_CHECKPOINTS.joinpath(\"biokg_transe_checkpoint.pt\")\n",
    ")\n",
    "# attach state to model\n",
    "pykeen_model.load_state_dict(model_checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions using self-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_label</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>relation_label</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>drugbank:DB00002</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>1319</td>\n",
       "      <td>mesh:D000077195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drugbank:DB00006</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>2243</td>\n",
       "      <td>mesh:D020521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>drugbank:DB00006</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>2286</td>\n",
       "      <td>mesh:D048909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>drugbank:DB00007</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>1930</td>\n",
       "      <td>mesh:D011629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>drugbank:DB00008</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>1344</td>\n",
       "      <td>mesh:D000740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   head_id        head_label  relation_id relation_label  tail_id  \\\n",
       "0        0  drugbank:DB00002            0         treats     1319   \n",
       "1        1  drugbank:DB00006            0         treats     2243   \n",
       "2        1  drugbank:DB00006            0         treats     2286   \n",
       "3        2  drugbank:DB00007            0         treats     1930   \n",
       "4        3  drugbank:DB00008            0         treats     1344   \n",
       "\n",
       "        tail_label  \n",
       "0  mesh:D000077195  \n",
       "1     mesh:D020521  \n",
       "2     mesh:D048909  \n",
       "3     mesh:D011629  \n",
       "4     mesh:D000740  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect test\n",
    "test.tensor_to_df(test.mapped_triples).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction dataframe for a given entry. Will make a ranked df of all entities possible in your dataset\n",
    "# ordered from most likely to least likely (as thought by the model)\n",
    "pred_df = pykeen.predict.predict_target(\n",
    "    model=pykeen_model, triples_factory=test, head=test[0][0], relation=test[0][1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained model\n",
    "* models come from rivas' paper\n",
    "* extract the files in the artifacts by using gunzip\n",
    "* two main steps: load the pre-trained model, then make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to need to first construct a Mapping[str, int] (aka a dictionary) for entities and relations passed to the model\n",
    "# these are found in the model directory and kindly provided by the authors (nice of them)\n",
    "\n",
    "# path to best model\n",
    "biokg_model = os.path.join(\n",
    "    \"/home/rogertu/projects/KGEM/models/biokg/transe/0000_user_data_transe/artifacts\",\n",
    "    str(configs[\"metadata\"][\"best_trial_number\"]),\n",
    ")\n",
    "\n",
    "# dataframes for entity and relation mappings\n",
    "e2id = pd.read_csv(\n",
    "    os.path.join(biokg_model, \"training_triples\", \"entity_to_id.tsv\"), sep=\"\\t\"\n",
    ")\n",
    "r2id = pd.read_csv(\n",
    "    os.path.join(biokg_model, \"training_triples\", \"relation_to_id.tsv\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# dictionary of e2id and r2id\n",
    "\n",
    "e2id_dict = dict(zip(e2id[\"label\"], e2id[\"id\"]))\n",
    "r2id_dict = dict(zip(r2id[\"label\"], r2id[\"id\"]))\n",
    "id2e_dict = dict(zip(e2id[\"id\"], e2id[\"label\"]))\n",
    "id2r_dict = dict(zip(r2id[\"id\"], r2id[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the translated training triples, just so we can see what the model is predicting\n",
    "# pl is polars, a faster version of pandas\n",
    "(\n",
    "    pl.read_csv(  # read dataframe\n",
    "        os.path.join(biokg_model, \"training_triples\", \"numeric_triples.tsv\"),\n",
    "        separator=\"\\t\",\n",
    "        entity_to_id=e2id_dict,\n",
    "    )\n",
    "    .with_columns(  # convert numeric to string\n",
    "        pl.col(\"head\").replace(id2e_dict),\n",
    "        pl.col(\"relation\").replace(id2r_dict),\n",
    "        pl.col(\"tail\").replace(id2e_dict),\n",
    "    )\n",
    "    .write_csv(  # export to translated_triples.tsv\n",
    "        os.path.join(biokg_model, \"training_triples\", \"translated_triples.tsv\"),\n",
    "        separator=\"\\t\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.triples.triples_factory:You're trying to map triples with 2 entities and 1 relations that are not in the training set. These triples will be excluded from the mapping.\n",
      "WARNING:pykeen.triples.triples_factory:In total 1 from 278084 triples were filtered out\n",
      "WARNING:pykeen.models.base:No random seed is specified. This may lead to non-reproducible results.\n",
      "/tmp/ipykernel_3639718/3586993380.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_checkpoint = torch.load(\n"
     ]
    }
   ],
   "source": [
    "# a model was already saved with the repository.\n",
    "# we can load the model and use it to predict on the test set\n",
    "# we however do need to know what the id2e and id2r mappings are otherwise predictions are non-sensical\n",
    "\n",
    "model_checkpoint = torch.load(\n",
    "    os.path.join(\n",
    "        biokg_model,\n",
    "        \"trained_model.pkl\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "* score the likelihood of a given triple\n",
    "* predict target given head/rel or rel/tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.predict import predict_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.triples.triples_factory:You're trying to map triples with 2 entities and 1 relations that are not in the training set. These triples will be excluded from the mapping.\n",
      "WARNING:pykeen.triples.triples_factory:In total 1 from 278084 triples were filtered out\n",
      "WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ScorePack(result=tensor([[    0,     0, 10859],\n",
       "        [    0,     1,  2416],\n",
       "        [    0,     1,  2581],\n",
       "        ...,\n",
       "        [44412,     0,  3352],\n",
       "        [44416,     0,  5246],\n",
       "        [44417,     0,  3889]]), scores=tensor([-11.3291, -11.0540,  -9.8589,  ..., -10.0577, -10.9170,  -8.7985]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_triples(\n",
    "    model=paper_pk_model,\n",
    "    triples=TriplesFactory.from_path(\n",
    "        os.path.join(biokg_model, \"training_triples\", \"translated_triples.tsv\"),\n",
    "        delimiter=\"\\t\",\n",
    "        entity_to_id=e2id_dict,\n",
    "        relation_to_id=r2id_dict,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.predict import predict_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_id</th>\n",
       "      <th>head_label</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>relation_label</th>\n",
       "      <th>tail_id</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>drugbank:DB00002</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>1319</td>\n",
       "      <td>mesh:D000077195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drugbank:DB00006</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>2243</td>\n",
       "      <td>mesh:D020521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>drugbank:DB00006</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>2286</td>\n",
       "      <td>mesh:D048909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>drugbank:DB00007</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>1930</td>\n",
       "      <td>mesh:D011629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>drugbank:DB00008</td>\n",
       "      <td>0</td>\n",
       "      <td>treats</td>\n",
       "      <td>1344</td>\n",
       "      <td>mesh:D000740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   head_id        head_label  relation_id relation_label  tail_id  \\\n",
       "0        0  drugbank:DB00002            0         treats     1319   \n",
       "1        1  drugbank:DB00006            0         treats     2243   \n",
       "2        1  drugbank:DB00006            0         treats     2286   \n",
       "3        2  drugbank:DB00007            0         treats     1930   \n",
       "4        3  drugbank:DB00008            0         treats     1344   \n",
       "\n",
       "        tail_label  \n",
       "0  mesh:D000077195  \n",
       "1     mesh:D020521  \n",
       "2     mesh:D048909  \n",
       "3     mesh:D011629  \n",
       "4     mesh:D000740  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tensor_to_df(test.mapped_triples).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.triples.triples_factory:You're trying to map triples with 2 entities and 1 relations that are not in the training set. These triples will be excluded from the mapping.\n",
      "WARNING:pykeen.triples.triples_factory:In total 1 from 278084 triples were filtered out\n"
     ]
    }
   ],
   "source": [
    "# make one prediction from the test set\n",
    "a_tail_predict = predict_target(\n",
    "    model=paper_pk_model,\n",
    "    head=\"drugbank:DB00002\",\n",
    "    relation=\"treats\",\n",
    "    triples_factory=TriplesFactory.from_path(\n",
    "        os.path.join(biokg_model, \"training_triples\", \"translated_triples.tsv\"),\n",
    "        delimiter=\"\\t\",\n",
    "        entity_to_id=e2id_dict,\n",
    "        relation_to_id=r2id_dict,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tail_id</th>\n",
       "      <th>score</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22233</th>\n",
       "      <td>2338</td>\n",
       "      <td>-9.570178</td>\n",
       "      <td>mesh:D000077195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tail_id     score       tail_label\n",
       "22233     2338 -9.570178  mesh:D000077195"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pandas to identify the true target for the head/rel pair. The rank here is 22,233 given the TransE model loaded.\n",
    "a_tail_predict.df.reset_index()[[\"tail_id\", \"score\", \"tail_label\"]].query(\n",
    "    'tail_label==\"mesh:D000077195\"'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
