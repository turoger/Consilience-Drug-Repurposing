{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample hyperparameter optimization run for TransE on MIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rogertu/python_venvs/RotatE/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../kge/codes/\")\n",
    "from dataloader import TestDataset, TrainDataset, BidirectionalOneShotIterator\n",
    "from run import parse_args\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy and paste the dataloader and relevant functions over.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# L119 in run.py\n",
    "def read_triple(file_path, entity2id, relation2id):\n",
    "    \"\"\"\n",
    "    Read triples and map them into ids.\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    with open(file_path) as fin:\n",
    "        for line in fin:\n",
    "            h, r, t = line.strip().split(\"\\t\")\n",
    "            triples.append((entity2id[h], relation2id[r], entity2id[t]))\n",
    "    return triples\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, save_variable_list, args):\n",
    "    \"\"\"\n",
    "    Save the parameters of the model and the optimizer,\n",
    "    as well as some other variables such as step and learning_rate\n",
    "    \"\"\"\n",
    "\n",
    "    argparse_dict = vars(args)\n",
    "    with open(os.path.join(args.save_path, \"config.json\"), \"w\") as fjson:\n",
    "        json.dump(argparse_dict, fjson)\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            **save_variable_list,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        },\n",
    "        os.path.join(args.save_path, \"checkpoint\"),\n",
    "    )\n",
    "\n",
    "    entity_embedding = model.entity_embedding.detach().cpu().numpy()\n",
    "    np.save(os.path.join(args.save_path, \"entity_embedding\"), entity_embedding)\n",
    "\n",
    "    relation_embedding = model.relation_embedding.detach().cpu().numpy()\n",
    "    np.save(os.path.join(args.save_path, \"relation_embedding\"), relation_embedding)\n",
    "\n",
    "\n",
    "def set_logger(args):\n",
    "    \"\"\"\n",
    "    Write logs to checkpoint and console\n",
    "    \"\"\"\n",
    "\n",
    "    if args.do_train:\n",
    "        log_file = os.path.join(args.save_path or args.init_checkpoint, \"train.log\")\n",
    "    else:\n",
    "        log_file = os.path.join(args.save_path or args.init_checkpoint, \"test.log\")\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "        level=logging.INFO,\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        filename=log_file,\n",
    "        filemode=\"w\",\n",
    "    )\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"%(asctime)s %(levelname)-8s %(message)s\")\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger(\"\").addHandler(console)\n",
    "\n",
    "\n",
    "def log_metrics(mode, step, metrics):\n",
    "    \"\"\"\n",
    "    Print the evaluation logs\n",
    "    \"\"\"\n",
    "    for metric in metrics:\n",
    "        logging.info(\"%s %s at step %d: %f\" % (mode, metric, step, metrics[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set relevant arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.data_path = \"/home/rogertu/projects/KnowledgeGraphEmbedding00/data/MIND_CtD/\"\n",
    "# more parameters\n",
    "args.uni_weight = True\n",
    "args.cpu_num = 10\n",
    "args.cuda = True\n",
    "args.model = \"TransE\"\n",
    "args.save_path = os.path.join(\n",
    "    \"/home/rogertu/projects/KnowledgeGraphEmbedding00/models/\",\n",
    "    args.model,\n",
    ")\n",
    "args.negative_adversarial_sampling = True\n",
    "args.gamma = 48  # controls embedding range.  (gamma+2)/hidden_dim\n",
    "# should range from +/-1 to 0.1667\n",
    "args.regularization = (\n",
    "    0.0  # controls loss, have it off for default, on for DistMult and ComplEx\n",
    ")\n",
    "args.save_checkpoint_steps = 10000\n",
    "args.valid_steps = 100000\n",
    "args.do_valid = True\n",
    "args.log_steps = 100\n",
    "args.test_log_steps = 10000\n",
    "\n",
    "args.double_entity_embedding = False  # False for TransE\n",
    "args.double_relation_embedding = False  # False for TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if args.save_path and not os.path.exists(args.save_path):\n",
    "    os.makedirs(args.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "with open(os.path.join(args.data_path, \"entities.dict\")) as fin:\n",
    "    entity2id = dict()\n",
    "    for line in fin:\n",
    "        eid, entity = line.strip().split(\"\\t\")\n",
    "        entity2id[entity] = int(eid)\n",
    "\n",
    "with open(os.path.join(args.data_path, \"relations.dict\")) as fin:\n",
    "    relation2id = dict()\n",
    "    for line in fin:\n",
    "        rid, relation = line.strip().split(\"\\t\")\n",
    "        relation2id[relation] = int(rid)\n",
    "\n",
    "nentity = len(entity2id)\n",
    "nrelation = len(relation2id)\n",
    "\n",
    "args.nentity = nentity\n",
    "args.nrelation = nrelation\n",
    "\n",
    "train_triples = read_triple(\n",
    "    os.path.join(args.data_path, \"train.txt\"), entity2id, relation2id\n",
    ")\n",
    "valid_triples = read_triple(\n",
    "    os.path.join(args.data_path, \"valid.txt\"), entity2id, relation2id\n",
    ")\n",
    "test_triples = read_triple(\n",
    "    os.path.join(args.data_path, \"test.txt\"), entity2id, relation2id\n",
    ")\n",
    "\n",
    "all_true_triples = train_triples + valid_triples + test_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.adversarial_temperature = 1.0  # default. Modulates negative effect on loss.\n",
    "args.test_batch_size = 4\n",
    "args.warm_up_steps = None\n",
    "args.countries = None\n",
    "args.optimizer = \"adam\"\n",
    "args.do_test = False\n",
    "args.do_predict = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define what constitutes a trial for each hyperparameter optimziation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    \"\"\"Set items to be optimized in this\"\"\"\n",
    "\n",
    "    # varied\n",
    "    args.batch_size = trial.suggest_int(f\"batch_size\", 64, 256, step=4)\n",
    "    args.negative_sample_size = trial.suggest_int(\n",
    "        f\"negative_sample_size\", 64, 128, step=4\n",
    "    )\n",
    "    args.hidden_dim = trial.suggest_int(f\"hidden_dimension_size\", 100, 300, step=25)\n",
    "    args.learning_rate = trial.suggest_float(f\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    args.max_steps = trial.suggest_int(\"max_steps\", 50000, 100000, step=10000)\n",
    "\n",
    "    # constant var can't be referenced outside of function?\n",
    "    # if args.warm_up_steps:\n",
    "    #    warm_up_steps = args.warm_up_steps\n",
    "    # else:\n",
    "    #    warm_up_steps = args.max_steps // 2\n",
    "\n",
    "    # model\n",
    "    kge_model = model.KGEModel(\n",
    "        model_name=args.model,\n",
    "        nentity=args.nentity,\n",
    "        nrelation=args.nrelation,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        gamma=args.gamma,\n",
    "        double_entity_embedding=args.double_entity_embedding,\n",
    "        double_relation_embedding=args.double_relation_embedding,\n",
    "    )\n",
    "\n",
    "    kge_model.cuda()\n",
    "\n",
    "    # load train data\n",
    "    train_dataloader_head = DataLoader(\n",
    "        TrainDataset(\n",
    "            train_triples, nentity, nrelation, args.negative_sample_size, \"head-batch\"\n",
    "        ),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=max(1, args.cpu_num // 2),\n",
    "        collate_fn=TrainDataset.collate_fn,\n",
    "    )\n",
    "\n",
    "    train_dataloader_tail = DataLoader(\n",
    "        TrainDataset(\n",
    "            train_triples, nentity, nrelation, args.negative_sample_size, \"tail-batch\"\n",
    "        ),\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=max(1, args.cpu_num // 2),\n",
    "        collate_fn=TrainDataset.collate_fn,\n",
    "    )\n",
    "    # every other sample will be head or tail\n",
    "    train_iterator = BidirectionalOneShotIterator(\n",
    "        train_dataloader_head, train_dataloader_tail\n",
    "    )\n",
    "\n",
    "    # Set training configuration and optimizer\n",
    "    current_learning_rate = args.learning_rate\n",
    "    if args.optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
    "            lr=current_learning_rate,\n",
    "        )\n",
    "    elif args.optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
    "            lr=current_learning_rate,\n",
    "        )\n",
    "    elif args.optimizer == \"adagrad\":\n",
    "        optimizer = torch.optim.Adagrad(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()),\n",
    "            lr=current_learning_rate,\n",
    "        )\n",
    "\n",
    "    # add in optimizer for steps otherwise LR doesn't really matter\n",
    "    training_logs = []\n",
    "    for step in range(0, args.max_steps):\n",
    "        log = kge_model.train_step(kge_model, optimizer, train_iterator, args)\n",
    "\n",
    "        training_logs.append(log)\n",
    "\n",
    "        if step % args.save_checkpoint_steps == 0:\n",
    "            save_variable_list = {\n",
    "                \"step\": step,\n",
    "                \"current_learning_rate\": current_learning_rate,\n",
    "                #'warm_up_steps': warm_up_steps\n",
    "            }\n",
    "            save_model(kge_model, optimizer, save_variable_list, args)\n",
    "\n",
    "        if step % args.log_steps == 0:\n",
    "            metrics = {}\n",
    "            for metric in training_logs[0].keys():\n",
    "                metrics[metric] = sum([log[metric] for log in training_logs]) / len(\n",
    "                    training_logs\n",
    "                )\n",
    "            log_metrics(\"Training average\", step, metrics)\n",
    "            training_logs = []\n",
    "\n",
    "        if args.do_valid and (step / (args.max_steps - 1) == 1):\n",
    "            logging.info(\"Evaluating on Valid Dataset...\")\n",
    "            metrics = kge_model.test_step(\n",
    "                kge_model, valid_triples, all_true_triples, args\n",
    "            )\n",
    "            log_metrics(\"Valid\", step, metrics)\n",
    "\n",
    "    save_variable_list = {\n",
    "        \"step\": step,\n",
    "        \"current_learning_rate\": current_learning_rate,\n",
    "        #'warm_up_steps': warm_up_steps\n",
    "    }\n",
    "    save_model(kge_model, optimizer, save_variable_list, args)\n",
    "\n",
    "    # return log['loss'] #for loss\n",
    "    torch.cuda.empty_cache()  # clear memory buildup from multiple models\n",
    "    return metrics[\"MRR\"]  # MRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup your optuna study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# other server url\n",
    "url=\"postgresql+psycopg2://root:su07dev@su07:5432/optuna_test\"\n",
    "```\n",
    "\n",
    "If you get an error that tells you that you need to update your optuna storage, follow the code below:\n",
    "```bash\n",
    "optuna storage upgrade --storage $STORAGE_URL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other server url\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=\"postgresql+psycopg2://rogertu:admin@localhost/optuna_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 21:09:18,542]\u001b[0m A new study created in RDB with name: TransE_MIND_CtD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create a new study.\n",
    "study = optuna.create_study(\n",
    "    study_name=\"TransE_MIND_CtD\",\n",
    "    direction=\"maximize\",\n",
    "    storage=storage,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-22 22:06:40,277]\u001b[0m Trial 0 finished with value: 0.009607338832682872 and parameters: {'batch_size': 168, 'negative_sample_size': 100, 'hidden_dimension_size': 250, 'learning_rate': 0.004145239582232327, 'max_steps': 90000}. Best is trial 0 with value: 0.009607338832682872.\u001b[0m\n",
      "\u001b[32m[I 2022-10-22 22:52:53,669]\u001b[0m Trial 1 finished with value: 0.0022293989672690267 and parameters: {'batch_size': 208, 'negative_sample_size': 116, 'hidden_dimension_size': 125, 'learning_rate': 0.00017446498144999613, 'max_steps': 100000}. Best is trial 0 with value: 0.009607338832682872.\u001b[0m\n",
      "\u001b[32m[I 2022-10-22 23:19:34,093]\u001b[0m Trial 2 finished with value: 0.008654065978562327 and parameters: {'batch_size': 228, 'negative_sample_size': 124, 'hidden_dimension_size': 100, 'learning_rate': 0.001806108189080781, 'max_steps': 60000}. Best is trial 0 with value: 0.009607338832682872.\u001b[0m\n",
      "\u001b[32m[I 2022-10-22 23:51:06,040]\u001b[0m Trial 3 finished with value: 0.011050940642967171 and parameters: {'batch_size': 256, 'negative_sample_size': 104, 'hidden_dimension_size': 200, 'learning_rate': 0.0015456785770274278, 'max_steps': 50000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 00:42:43,530]\u001b[0m Trial 4 finished with value: 0.00921062970871197 and parameters: {'batch_size': 108, 'negative_sample_size': 92, 'hidden_dimension_size': 250, 'learning_rate': 0.005875333408931876, 'max_steps': 70000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 01:18:01,668]\u001b[0m Trial 5 finished with value: 0.0007038281776393796 and parameters: {'batch_size': 100, 'negative_sample_size': 68, 'hidden_dimension_size': 100, 'learning_rate': 0.00045734361078541376, 'max_steps': 90000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 02:27:55,326]\u001b[0m Trial 6 finished with value: 0.008902543156505578 and parameters: {'batch_size': 112, 'negative_sample_size': 84, 'hidden_dimension_size': 275, 'learning_rate': 0.006632317021719425, 'max_steps': 90000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 03:02:30,219]\u001b[0m Trial 7 finished with value: 0.00140142138591065 and parameters: {'batch_size': 196, 'negative_sample_size': 120, 'hidden_dimension_size': 225, 'learning_rate': 0.0002097016106595248, 'max_steps': 50000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 03:39:16,509]\u001b[0m Trial 8 finished with value: 0.005353500711649398 and parameters: {'batch_size': 108, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0039430432458979914, 'max_steps': 50000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 04:20:49,478]\u001b[0m Trial 9 finished with value: 0.0005290462030508846 and parameters: {'batch_size': 228, 'negative_sample_size': 124, 'hidden_dimension_size': 150, 'learning_rate': 0.0001496026163206342, 'max_steps': 90000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 05:03:45,999]\u001b[0m Trial 10 finished with value: 0.010427055309221386 and parameters: {'batch_size': 256, 'negative_sample_size': 64, 'hidden_dimension_size': 175, 'learning_rate': 0.001008289564812403, 'max_steps': 70000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 05:43:34,953]\u001b[0m Trial 11 finished with value: 0.01055511129935721 and parameters: {'batch_size': 252, 'negative_sample_size': 64, 'hidden_dimension_size': 175, 'learning_rate': 0.0011402002902415893, 'max_steps': 70000}. Best is trial 3 with value: 0.011050940642967171.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 06:21:45,022]\u001b[0m Trial 12 finished with value: 0.014330860699345948 and parameters: {'batch_size': 256, 'negative_sample_size': 108, 'hidden_dimension_size': 200, 'learning_rate': 0.0013182879607109984, 'max_steps': 60000}. Best is trial 12 with value: 0.014330860699345948.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 06:56:47,937]\u001b[0m Trial 13 finished with value: 0.014048077194551707 and parameters: {'batch_size': 156, 'negative_sample_size': 108, 'hidden_dimension_size': 200, 'learning_rate': 0.0020928893274099374, 'max_steps': 60000}. Best is trial 12 with value: 0.014330860699345948.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 07:35:06,079]\u001b[0m Trial 14 finished with value: 0.004938589040791759 and parameters: {'batch_size': 152, 'negative_sample_size': 108, 'hidden_dimension_size': 200, 'learning_rate': 0.0004822810787462147, 'max_steps': 60000}. Best is trial 12 with value: 0.014330860699345948.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 08:14:54,199]\u001b[0m Trial 15 finished with value: 0.008824234412673267 and parameters: {'batch_size': 68, 'negative_sample_size': 112, 'hidden_dimension_size': 225, 'learning_rate': 0.0025204862680693104, 'max_steps': 60000}. Best is trial 12 with value: 0.014330860699345948.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 09:15:59,114]\u001b[0m Trial 16 finished with value: 0.008406872885509516 and parameters: {'batch_size': 156, 'negative_sample_size': 84, 'hidden_dimension_size': 300, 'learning_rate': 0.0005292552852493527, 'max_steps': 80000}. Best is trial 12 with value: 0.014330860699345948.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 09:45:37,629]\u001b[0m Trial 17 finished with value: 0.0048011630255776535 and parameters: {'batch_size': 180, 'negative_sample_size': 88, 'hidden_dimension_size': 150, 'learning_rate': 0.009547706818493146, 'max_steps': 60000}. Best is trial 12 with value: 0.014330860699345948.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 10:28:39,191]\u001b[0m Trial 18 finished with value: 0.011040421877037378 and parameters: {'batch_size': 136, 'negative_sample_size': 76, 'hidden_dimension_size': 175, 'learning_rate': 0.002887094964942697, 'max_steps': 80000}. Best is trial 12 with value: 0.014330860699345948.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 11:07:28,085]\u001b[0m Trial 19 finished with value: 0.008424598183672957 and parameters: {'batch_size': 132, 'negative_sample_size': 128, 'hidden_dimension_size': 225, 'learning_rate': 0.0008128728163040385, 'max_steps': 60000}. Best is trial 12 with value: 0.014330860699345948.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 11:35:41,148]\u001b[0m Trial 20 finished with value: 0.015154167947527483 and parameters: {'batch_size': 192, 'negative_sample_size': 108, 'hidden_dimension_size': 200, 'learning_rate': 0.0018465823152578173, 'max_steps': 50000}. Best is trial 20 with value: 0.015154167947527483.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 12:05:50,398]\u001b[0m Trial 21 finished with value: 0.011438224058520855 and parameters: {'batch_size': 188, 'negative_sample_size': 108, 'hidden_dimension_size': 200, 'learning_rate': 0.002036682038469749, 'max_steps': 50000}. Best is trial 20 with value: 0.015154167947527483.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 12:37:53,663]\u001b[0m Trial 22 finished with value: 0.012790418155878367 and parameters: {'batch_size': 220, 'negative_sample_size': 100, 'hidden_dimension_size': 200, 'learning_rate': 0.0013795038376079273, 'max_steps': 50000}. Best is trial 20 with value: 0.015154167947527483.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 13:08:08,900]\u001b[0m Trial 23 finished with value: 0.006768141276125162 and parameters: {'batch_size': 176, 'negative_sample_size': 112, 'hidden_dimension_size': 150, 'learning_rate': 0.0007360531512252408, 'max_steps': 60000}. Best is trial 20 with value: 0.015154167947527483.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 13:56:29,739]\u001b[0m Trial 24 finished with value: 0.015098094144807808 and parameters: {'batch_size': 204, 'negative_sample_size': 116, 'hidden_dimension_size': 225, 'learning_rate': 0.0032356840687121284, 'max_steps': 70000}. Best is trial 20 with value: 0.015154167947527483.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 14:48:18,015]\u001b[0m Trial 25 finished with value: 0.017278602152089505 and parameters: {'batch_size': 240, 'negative_sample_size': 116, 'hidden_dimension_size': 250, 'learning_rate': 0.0034802494249275197, 'max_steps': 70000}. Best is trial 25 with value: 0.017278602152089505.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 15:44:33,279]\u001b[0m Trial 26 finished with value: 0.013984063041572766 and parameters: {'batch_size': 208, 'negative_sample_size': 116, 'hidden_dimension_size': 250, 'learning_rate': 0.0034551453051686193, 'max_steps': 80000}. Best is trial 25 with value: 0.017278602152089505.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 16:42:00,434]\u001b[0m Trial 27 finished with value: 0.010257265270983706 and parameters: {'batch_size': 236, 'negative_sample_size': 120, 'hidden_dimension_size': 275, 'learning_rate': 0.004774053350509807, 'max_steps': 70000}. Best is trial 25 with value: 0.017278602152089505.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 17:47:33,147]\u001b[0m Trial 28 finished with value: 0.010870137262907672 and parameters: {'batch_size': 204, 'negative_sample_size': 128, 'hidden_dimension_size': 300, 'learning_rate': 0.009628381104943155, 'max_steps': 80000}. Best is trial 25 with value: 0.017278602152089505.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 18:56:25,372]\u001b[0m Trial 29 finished with value: 0.016052883494431756 and parameters: {'batch_size': 240, 'negative_sample_size': 100, 'hidden_dimension_size': 250, 'learning_rate': 0.002886157404329651, 'max_steps': 100000}. Best is trial 25 with value: 0.017278602152089505.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 20:12:54,136]\u001b[0m Trial 30 finished with value: 0.009474824967829969 and parameters: {'batch_size': 240, 'negative_sample_size': 100, 'hidden_dimension_size': 250, 'learning_rate': 0.005437957808312751, 'max_steps': 100000}. Best is trial 25 with value: 0.017278602152089505.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 21:26:21,938]\u001b[0m Trial 31 finished with value: 0.0148305453958219 and parameters: {'batch_size': 216, 'negative_sample_size': 116, 'hidden_dimension_size': 225, 'learning_rate': 0.003038877334073798, 'max_steps': 100000}. Best is trial 25 with value: 0.017278602152089505.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 22:21:17,976]\u001b[0m Trial 32 finished with value: 0.01672311877428678 and parameters: {'batch_size': 240, 'negative_sample_size': 104, 'hidden_dimension_size': 250, 'learning_rate': 0.0025223905309978267, 'max_steps': 70000}. Best is trial 25 with value: 0.017278602152089505.\u001b[0m\n",
      "\u001b[32m[I 2022-10-23 23:27:12,941]\u001b[0m Trial 33 finished with value: 0.022458976559196084 and parameters: {'batch_size': 240, 'negative_sample_size': 104, 'hidden_dimension_size': 275, 'learning_rate': 0.0023420886731308054, 'max_steps': 80000}. Best is trial 33 with value: 0.022458976559196084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 00:49:20,508]\u001b[0m Trial 34 finished with value: 0.0206325029151057 and parameters: {'batch_size': 240, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0023102856219185193, 'max_steps': 100000}. Best is trial 33 with value: 0.022458976559196084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 01:55:31,667]\u001b[0m Trial 35 finished with value: 0.007538295746106709 and parameters: {'batch_size': 224, 'negative_sample_size': 92, 'hidden_dimension_size': 275, 'learning_rate': 0.0073249816608307785, 'max_steps': 80000}. Best is trial 33 with value: 0.022458976559196084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 03:10:59,796]\u001b[0m Trial 36 finished with value: 0.00955277816516185 and parameters: {'batch_size': 244, 'negative_sample_size': 96, 'hidden_dimension_size': 300, 'learning_rate': 0.004550726844086497, 'max_steps': 90000}. Best is trial 33 with value: 0.022458976559196084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 04:07:24,104]\u001b[0m Trial 37 finished with value: 0.01598205518945749 and parameters: {'batch_size': 232, 'negative_sample_size': 104, 'hidden_dimension_size': 275, 'learning_rate': 0.0023124024491684107, 'max_steps': 70000}. Best is trial 33 with value: 0.022458976559196084.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 05:18:49,049]\u001b[0m Trial 38 finished with value: 0.0238312070203215 and parameters: {'batch_size': 216, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.001853336864281406, 'max_steps': 90000}. Best is trial 38 with value: 0.0238312070203215.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 06:33:52,782]\u001b[0m Trial 39 finished with value: 0.021984564910524557 and parameters: {'batch_size': 216, 'negative_sample_size': 92, 'hidden_dimension_size': 300, 'learning_rate': 0.0015321736064027908, 'max_steps': 90000}. Best is trial 38 with value: 0.0238312070203215.\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 07:49:56,888]\u001b[0m Trial 40 finished with value: 0.01793390247696646 and parameters: {'batch_size': 212, 'negative_sample_size': 80, 'hidden_dimension_size': 300, 'learning_rate': 0.0016133860128808943, 'max_steps': 90000}. Best is trial 38 with value: 0.0238312070203215.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 09:22:22,101]\u001b[0m Trial 61 finished with value: 0.021041811752326885 and parameters: {'batch_size': 196, 'negative_sample_size': 100, 'hidden_dimension_size': 300, 'learning_rate': 0.0019120964118685727, 'max_steps': 80000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 10:29:44,648]\u001b[0m Trial 62 finished with value: 0.02108886703664958 and parameters: {'batch_size': 212, 'negative_sample_size': 96, 'hidden_dimension_size': 300, 'learning_rate': 0.0011534219309049028, 'max_steps': 80000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 11:37:01,302]\u001b[0m Trial 63 finished with value: 0.020577313183150103 and parameters: {'batch_size': 204, 'negative_sample_size': 88, 'hidden_dimension_size': 300, 'learning_rate': 0.0017491212206899283, 'max_steps': 80000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 12:41:22,833]\u001b[0m Trial 64 finished with value: 0.016969181139072365 and parameters: {'batch_size': 188, 'negative_sample_size': 104, 'hidden_dimension_size': 275, 'learning_rate': 0.002169579215091589, 'max_steps': 80000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 13:58:28,310]\u001b[0m Trial 65 finished with value: 0.021009889631384532 and parameters: {'batch_size': 224, 'negative_sample_size': 92, 'hidden_dimension_size': 300, 'learning_rate': 0.0026786454748199294, 'max_steps': 90000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 15:08:26,651]\u001b[0m Trial 66 finished with value: 0.026796880346782397 and parameters: {'batch_size': 256, 'negative_sample_size': 100, 'hidden_dimension_size': 275, 'learning_rate': 0.0015277630319267823, 'max_steps': 90000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 16:20:23,831]\u001b[0m Trial 67 finished with value: 0.02467472997222942 and parameters: {'batch_size': 256, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0011925736427683261, 'max_steps': 90000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 17:34:17,319]\u001b[0m Trial 68 finished with value: 0.018844051716959166 and parameters: {'batch_size': 256, 'negative_sample_size': 112, 'hidden_dimension_size': 250, 'learning_rate': 0.0012534607598297808, 'max_steps': 100000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 18:17:31,779]\u001b[0m Trial 69 finished with value: 0.004930234501359069 and parameters: {'batch_size': 248, 'negative_sample_size': 100, 'hidden_dimension_size': 125, 'learning_rate': 0.0006552870751720206, 'max_steps': 90000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 19:34:46,036]\u001b[0m Trial 70 finished with value: 0.01876942543354147 and parameters: {'batch_size': 248, 'negative_sample_size': 72, 'hidden_dimension_size': 275, 'learning_rate': 0.0010696949785712338, 'max_steps': 100000}. Best is trial 46 with value: 0.027042151522385982.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 20:47:59,883]\u001b[0m Trial 71 finished with value: 0.027441743017920704 and parameters: {'batch_size': 256, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0014758180913550004, 'max_steps': 90000}. Best is trial 71 with value: 0.027441743017920704.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 22:02:04,141]\u001b[0m Trial 72 finished with value: 0.02000734140684666 and parameters: {'batch_size': 248, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0014795746615471454, 'max_steps': 90000}. Best is trial 71 with value: 0.027441743017920704.\u001b[0m\n",
      "\u001b[32m[I 2022-10-25 23:15:43,686]\u001b[0m Trial 73 finished with value: 0.011109785481295025 and parameters: {'batch_size': 252, 'negative_sample_size': 104, 'hidden_dimension_size': 275, 'learning_rate': 0.003818256305254381, 'max_steps': 90000}. Best is trial 71 with value: 0.027441743017920704.\u001b[0m\n",
      "\u001b[32m[I 2022-10-26 00:22:38,309]\u001b[0m Trial 74 finished with value: 0.014452188135324385 and parameters: {'batch_size': 256, 'negative_sample_size': 96, 'hidden_dimension_size': 250, 'learning_rate': 0.0008508241338910548, 'max_steps': 90000}. Best is trial 71 with value: 0.027441743017920704.\u001b[0m\n",
      "\u001b[32m[I 2022-10-26 01:35:39,746]\u001b[0m Trial 75 finished with value: 0.01984853533068059 and parameters: {'batch_size': 232, 'negative_sample_size': 108, 'hidden_dimension_size': 250, 'learning_rate': 0.0021291856516502707, 'max_steps': 100000}. Best is trial 71 with value: 0.027441743017920704.\u001b[0m\n",
      "\u001b[32m[I 2022-10-26 02:51:22,228]\u001b[0m Trial 76 finished with value: 0.018503364011201895 and parameters: {'batch_size': 236, 'negative_sample_size': 84, 'hidden_dimension_size': 275, 'learning_rate': 0.0009827367328687497, 'max_steps': 90000}. Best is trial 71 with value: 0.027441743017920704.\u001b[0m\n",
      "\u001b[32m[I 2022-10-26 03:40:38,412]\u001b[0m Trial 77 finished with value: 0.02545048945754103 and parameters: {'batch_size': 244, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0016156588392425295, 'max_steps': 90000}. Best is trial 71 with value: 0.027441743017920704.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(define_model, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Best Trial\n",
    "```Python\n",
    "FrozenTrial(number=71, values=[0.027441743017920704], datetime_start=datetime.datetime(2022, 10, 25, 19, 34, 46, 44677), datetime_complete=datetime.datetime(2022, 10, 25, 20, 47, 59, 858900), params={'batch_size': 256, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0014758180913550004, 'max_steps': 90000}, distributions={'batch_size': IntDistribution(high=256, log=False, low=64, step=4), 'negative_sample_size': IntDistribution(high=128, log=False, low=64, step=4), 'hidden_dimension_size': IntDistribution(high=300, log=False, low=100, step=25), 'learning_rate': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'max_steps': IntDistribution(high=100000, log=False, low=50000, step=10000)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1135, state=TrialState.COMPLETE, value=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=71, values=[0.027441743017920704], datetime_start=datetime.datetime(2022, 10, 25, 19, 34, 46, 44677), datetime_complete=datetime.datetime(2022, 10, 25, 20, 47, 59, 858900), params={'batch_size': 256, 'negative_sample_size': 96, 'hidden_dimension_size': 275, 'learning_rate': 0.0014758180913550004, 'max_steps': 90000}, distributions={'batch_size': IntDistribution(high=256, log=False, low=64, step=4), 'negative_sample_size': IntDistribution(high=128, log=False, low=64, step=4), 'hidden_dimension_size': IntDistribution(high=300, log=False, low=100, step=25), 'learning_rate': FloatDistribution(high=0.01, log=True, low=0.0001, step=None), 'max_steps': IntDistribution(high=100000, log=False, low=50000, step=10000)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=1135, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Important parameters output\n",
    "```Python\n",
    "OrderedDict([('learning_rate', 0.616334598857384),\n",
    "             ('max_steps', 0.12996281990864547),\n",
    "             ('hidden_dimension_size', 0.12604799029348462),\n",
    "             ('batch_size', 0.06826465838004579),\n",
    "             ('negative_sample_size', 0.05938993256044008)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.616334598857384),\n",
       "             ('max_steps', 0.12996281990864547),\n",
       "             ('hidden_dimension_size', 0.12604799029348462),\n",
       "             ('batch_size', 0.06826465838004579),\n",
       "             ('negative_sample_size', 0.05938993256044008)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna.importance.get_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear your torch memory\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
